{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### SORT ACCORDING TO COLUMN\n",
    "###\n",
    "\n",
    "import sys, csv ,operator\n",
    "data = csv.reader(open('../INPUT_data/publishers.csv'))\n",
    "sortedlist = sorted(data, key=operator.itemgetter(1))    # 1 specifies according to first column we want to sort\n",
    "#now write the sorted result into new CSV file\n",
    "with open(\"../INPUT_data/publishers_sorted.csv\", \"w\") as f:\n",
    "  fileWriter = csv.writer(f, delimiter=',')\n",
    "  for row in sortedlist:\n",
    "      fileWriter.writerow(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenante\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### DEDUPLICATE DATA PUBLISHERS\n",
    "### Check manually at the end\n",
    "###\n",
    "\n",
    "import sys, csv ,operator\n",
    "reader=csv.reader(open('../INPUT_data/publishers_sorted.csv', 'r'), delimiter=',')\n",
    "writer=csv.writer(open('../INPUT_data/publishers_sorted_distinct.csv', 'w'), delimiter=',')\n",
    "entries = set()\n",
    "\n",
    "for row in reader:\n",
    "   key = (row[0], row[1]) # instead of just the last name\n",
    "\n",
    "   if key not in entries:\n",
    "      writer.writerow(row)\n",
    "      entries.add(key)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### DEDUPLICATE DATA PERIODICALS  (using Pandas)\n",
    "### Check manually at the end\n",
    "###\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "file_name = \"../INPUT_data/periodicals.csv\"\n",
    "file_name_output = \"../INPUT_data/periodicals_distinct.csv\"\n",
    "\n",
    "df = pd.read_csv(file_name, sep=\"\\t or ,\")\n",
    "\n",
    "# Notes:\n",
    "# - the `subset=None` means that every column is used \n",
    "#    to determine if two rows are different; to change that specify\n",
    "#    the columns as an array\n",
    "# - the `inplace=True` means that the data structure is changed and\n",
    "#   the duplicate rows are gone  \n",
    "df.drop_duplicates(subset=None, inplace=True)\n",
    "\n",
    "# Write the results to a different file\n",
    "df.to_csv(file_name_output)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### DEDUPLICATE DATA AUTHORS  (using Pandas)\n",
    "### Check manually at the end\n",
    "###\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "file_name = \"../INPUT_data/authors.csv\"\n",
    "file_name_output = \"../INPUT_data/authors_distinct.csv\"\n",
    "\n",
    "df = pd.read_csv(file_name, sep=\"\\t or ,\")\n",
    "\n",
    "# Notes:\n",
    "# - the `subset=None` means that every column is used \n",
    "#    to determine if two rows are different; to change that specify\n",
    "#    the columns as an array\n",
    "# - the `inplace=True` means that the data structure is changed and\n",
    "#   the duplicate rows are gone  \n",
    "df.drop_duplicates(subset=None, inplace=True)\n",
    "\n",
    "# Write the results to a different file\n",
    "df.to_csv(file_name_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTHORS distinguish name and surname\n",
    "###\n",
    "\n",
    "import csv\n",
    "\n",
    "f = open('../INPUT_data/authors_distinct.csv')\n",
    "o = open('../INPUT_data/authors_distinct_surname_name2.csv', 'w')\n",
    "\n",
    "csv_f = csv.reader(f)   \n",
    "data = []\n",
    "\n",
    "for row in csv_f: \n",
    "   data.append(row)\n",
    "f.close()\n",
    "\n",
    "writer = csv.writer(o, quoting=csv.QUOTE_ALL)\n",
    "for row in data[1:]:\n",
    "    author = row[0]\n",
    "    surname = author.partition(' ')[2] \n",
    "    name = author.partition(' ')[0]\n",
    "    new_author = [surname, name]\n",
    "    writer.writerow([new_author])\n",
    "\n",
    "o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### READ THE CSV (just to check)\n",
    "###\n",
    "\n",
    "import csv\n",
    "\n",
    "f = open('../INPUT_data/publishers_sorted_distinct_manuallychecked.csv')\n",
    "csv_f = csv.reader(f)   \n",
    "data = []\n",
    "\n",
    "for row in csv_f: \n",
    "   data.append(row)\n",
    "f.close()\n",
    "\n",
    "## TEST COSA C'È NELLE LINEE SPECIFICATE\n",
    "## print(data[1:3])\n",
    "\n",
    "for row in data[1:]:\n",
    "    \n",
    "    if (row[0] == ''):\n",
    "        print('hello')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### CREATE XML FROM CSV (PUBLISHERS)\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from xml.etree import ElementTree as ET\n",
    "import csv\n",
    "\n",
    "f = open('../INPUT_data/publishers_sorted_distinct_manuallychecked.csv')\n",
    "o = open('../OUTPUT_xml/publishers.xml', 'w')\n",
    "\n",
    "csv_f = csv.reader(f)   \n",
    "data = []\n",
    "\n",
    "for row in csv_f: \n",
    "   data.append(row)\n",
    "f.close()\n",
    "\n",
    "## TEST COSA C'È NELLE LINEE SPECIFICATE\n",
    "## print(data[1:3])\n",
    "\n",
    "## WRITE DECLARATIONS AND BEGINNING OF THE XML FILE -adding more line breaks for readibility '+'\\n'+' ???-\n",
    "o.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>'+'\\n'+'<knoraXmlImport:resources xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/knoraXmlImport/v1# ../p0112-roud-oeuvres-xml-schemas/p0112-roud-oeuvres.xsd\" xmlns=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\" xmlns:p0112-roud-oeuvres=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\">'+'\\n')\n",
    "\n",
    "\n",
    "## WRITE ITEMS TO FILE\n",
    "for row in data[0:]:\n",
    "    \n",
    "    publisherLocation = row[0] \n",
    "    publisherName = row[1]\n",
    "    word_list = row[1].replace(\"'\", ' ') ## replace accent with space\n",
    "    word_list = word_list.replace(\",\", '').split()  ## replace comma with nothing and split words\n",
    "    words = '_'.join(word_list)     \n",
    "    \n",
    "    ## registering namespace\n",
    "    NS_ROUD = \"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" \n",
    "    NS_KNORAIMPORT = \"http://api.knora.org/ontology/knoraXmlImport/v1#\"\n",
    "    ET.register_namespace(\"p0112-roud-oeuvres\", NS_ROUD)\n",
    "    ET.register_namespace(\"knoraXmlImport\", NS_KNORAIMPORT)\n",
    "\n",
    "    ## define elements with ns\n",
    "    PublisherNS = ET.QName(NS_ROUD, \"Publisher\")\n",
    "    labelNS = ET.QName(NS_KNORAIMPORT, \"label\")\n",
    "    publisherHasLocationNS = ET.QName(NS_ROUD, \"publisherHasLocation\")\n",
    "    publisherHasNameNS = ET.QName(NS_ROUD, \"publisherHasName\")\n",
    "\n",
    "    ## create elements (as previously defined with ns)\n",
    "    Publisher = ET.Element(PublisherNS, attrib={'id':words}) \n",
    "    label = ET.SubElement(Publisher, labelNS)\n",
    "    label.text = \"edi_\"+publisherName\n",
    "    \n",
    "    ## if row is empty, don't create element, otherwise the import will fail (of course only for properties that are not mandatory)\n",
    "    if (row[0] == ''):\n",
    "        print()\n",
    "    else:\n",
    "        publisherHasLocation = ET.SubElement(Publisher, publisherHasLocationNS, attrib={'knoraType':'richtext_value'})\n",
    "        publisherHasLocation.text = publisherLocation ## use variable defined with location of the publisher corresponding to first row\n",
    "    \n",
    "    publisherHasName = ET.SubElement(Publisher, publisherHasNameNS, attrib={'knoraType':'richtext_value'})\n",
    "    publisherHasName.text = publisherName  ## use variable defined with name of the publisher corresponding to second row\n",
    "    \n",
    "    tree = ET.tostring(Publisher, encoding=\"unicode\")\n",
    "    o.write('\\n''\\n'+ tree)\n",
    "\n",
    "## WRITE END OF THE XML FILE\n",
    "with o:  ## this is to append the text, if just write o.write does not work here (why??)\n",
    "    o.write('\\n'+'</knoraXmlImport:resources>')\n",
    "\n",
    "o.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### CREATE XML FROM CSV (PERIODICALS)\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from xml.etree import ElementTree as ET\n",
    "import csv, re\n",
    "\n",
    "f = open('../INPUT_data/periodicals_distinct.csv')\n",
    "o = open('../OUTPUT_xml/periodicals.xml', 'w')\n",
    "\n",
    "csv_f = csv.reader(f)   \n",
    "data = []\n",
    "\n",
    "for row in csv_f: \n",
    "   data.append(row)\n",
    "f.close()\n",
    "\n",
    "## TEST COSA C'È NELLE LINEE SPECIFICATE\n",
    "## print(data[1:3])\n",
    "\n",
    "## WRITE DECLARATIONS AND BEGINNING OF THE XML FILE -adding more line breaks for readibility '+'\\n'+' ???-\n",
    "o.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>'+'\\n'+'<knoraXmlImport:resources xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/knoraXmlImport/v1# ../p0112-roud-oeuvres-xml-schemas/p0112-roud-oeuvres.xsd\" xmlns=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\" xmlns:p0112-roud-oeuvres=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\">'+'\\n')\n",
    "\n",
    "\n",
    "## WRITE ITEMS TO FILE\n",
    "for row in data[0:]:\n",
    "    \n",
    "    periodicalTitle = row[0] \n",
    "    labelPeriodicalTitle = row[0].replace('\"', '')  ## in label \" not accepted\n",
    "    word_list = re.split(', |\\(|/', labelPeriodicalTitle) ## split at comma, parenthesis or slash and take the first part (take the first part is below), using labelPeriodicalTitle where quotes have been already deleted\n",
    "    word_list = word_list[0].replace(\"'\", ' ').replace(\",\", '').split()  ## replace accent with space and replace comma with nothing and split words\n",
    "    words = '_'.join(word_list) \n",
    "    \n",
    "    ## registering namespace\n",
    "    NS_ROUD = \"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" \n",
    "    NS_KNORAIMPORT = \"http://api.knora.org/ontology/knoraXmlImport/v1#\"\n",
    "    ET.register_namespace(\"p0112-roud-oeuvres\", NS_ROUD)\n",
    "    ET.register_namespace(\"knoraXmlImport\", NS_KNORAIMPORT)\n",
    "\n",
    "    ## define elements with ns\n",
    "    PeriodicalNS = ET.QName(NS_ROUD, \"Periodical\")\n",
    "    labelNS = ET.QName(NS_KNORAIMPORT, \"label\")\n",
    "    periodicalHasTitleNS = ET.QName(NS_ROUD, \"periodicalHasTitle\")\n",
    "\n",
    "    ## create elements (as previously defined with ns)\n",
    "    Periodical = ET.Element(PeriodicalNS, attrib={'id':words}) \n",
    "    label = ET.SubElement(Periodical, labelNS)\n",
    "    label.text = \"period_\"+labelPeriodicalTitle\n",
    "    periodicalHasTitle = ET.SubElement(Periodical, periodicalHasTitleNS, attrib={'knoraType':'richtext_value'})\n",
    "    periodicalHasTitle.text = periodicalTitle  ## use variable defined with name of the publisher corresponding to second row\n",
    "    \n",
    "    tree = ET.tostring(Periodical, encoding=\"unicode\")\n",
    "    o.write('\\n''\\n'+ tree)\n",
    "\n",
    "## WRITE END OF THE XML FILE\n",
    "with o:  ## this is to append the text, if just write o.write does not work here (why??)\n",
    "    o.write('\\n'+'</knoraXmlImport:resources>')\n",
    "\n",
    "o.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### CREATE XML FROM CSV (AUTHORS)\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from xml.etree import ElementTree as ET\n",
    "import csv, re\n",
    "\n",
    "f = open('../INPUT_data/authors_distinct_surname_name.csv')\n",
    "o = open('../OUTPUT_xml/authors.xml', 'w')\n",
    "\n",
    "csv_f = csv.reader(f)   \n",
    "data = []\n",
    "\n",
    "for row in csv_f: \n",
    "   data.append(row)\n",
    "f.close()\n",
    "\n",
    "## TEST COSA C'È NELLE LINEE SPECIFICATE\n",
    "## print(data[1:3])\n",
    "\n",
    "## WRITE DECLARATIONS AND BEGINNING OF THE XML FILE -adding more line breaks for readibility '+'\\n'+' ???-\n",
    "o.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>'+'\\n'+'<knoraXmlImport:resources xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/knoraXmlImport/v1# ../p0112-roud-oeuvres-xml-schemas/p0112-roud-oeuvres.xsd\" xmlns=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\" xmlns:p0112-roud-oeuvres=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\">'+'\\n')\n",
    "\n",
    "\n",
    "## WRITE ITEMS TO FILE\n",
    "for row in data[0:]:\n",
    "    \n",
    "    surname = row[1]\n",
    "    name = row[0]\n",
    "    #### for building id\n",
    "    if len(surname.split()) > 1:  ## if long name and surname\n",
    "        surnameid = '_'.join(re.split(' ', surname))\n",
    "    else:\n",
    "        surnameid = surname\n",
    "    if len(name.split()) > 1:\n",
    "        nameid = '_'.join(re.split(' ', name))\n",
    "    else:\n",
    "        nameid = name\n",
    "    if (row[0] == ''):  ## if author has only surname\n",
    "        authorid = (surnameid).replace(\"'\", '').replace(\"(\", '').replace(\")\", '')\n",
    "    else:\n",
    "        authorid = (surnameid+'_'+nameid).replace(\"'\", '').replace(\"(\", '').replace(\")\", '') \n",
    "   \n",
    "\n",
    "    \n",
    "    ## registering namespace\n",
    "    NS_ROUD = \"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" \n",
    "    NS_KNORAIMPORT = \"http://api.knora.org/ontology/knoraXmlImport/v1#\"\n",
    "    ET.register_namespace(\"p0112-roud-oeuvres\", NS_ROUD)\n",
    "    ET.register_namespace(\"knoraXmlImport\", NS_KNORAIMPORT)\n",
    "\n",
    "    ## define elements with ns\n",
    "    AuthorNS = ET.QName(NS_ROUD, \"Author\")  \n",
    "    labelNS = ET.QName(NS_KNORAIMPORT, \"label\")\n",
    "    AuthorHasFamilyNameNS = ET.QName(NS_ROUD, \"authorHasFamilyName\")\n",
    "    AuthorHasGivenNameNS = ET.QName(NS_ROUD, \"authorHasGivenName\")\n",
    "\n",
    "    ## create elements (as previously defined with ns)\n",
    "    \n",
    "    \n",
    "    \n",
    "    Author = ET.Element(AuthorNS, attrib={'id':authorid}) \n",
    "    label = ET.SubElement(Author, labelNS)\n",
    "    if (row[0] == ''):  ## if author has surname and name\n",
    "        label.text = \"aut_\"+surname\n",
    "        authorHasFamilyName = ET.SubElement(Author, AuthorHasFamilyNameNS, attrib={'knoraType':'richtext_value'})\n",
    "        authorHasFamilyName.text = surname  ## \n",
    "    else:\n",
    "        label.text = \"aut_\"+surname+\" \"+name\n",
    "        authorHasFamilyName = ET.SubElement(Author, AuthorHasFamilyNameNS, attrib={'knoraType':'richtext_value'})\n",
    "        authorHasFamilyName.text = surname  ## \n",
    "        authorHasGivenName = ET.SubElement(Author, AuthorHasGivenNameNS, attrib={'knoraType':'richtext_value'})\n",
    "        authorHasGivenName.text = name  ## \n",
    "    \n",
    "    tree = ET.tostring(Author, encoding=\"unicode\")\n",
    "    o.write('\\n''\\n'+ tree)\n",
    "\n",
    "## WRITE END OF THE XML FILE\n",
    "with o:  ## this is to append the text, if just write o.write does not work here (why??)\n",
    "    o.write('\\n'+'</knoraXmlImport:resources>')\n",
    "\n",
    "o.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### CREATE XML FROM CSV (ARTICLES)\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "from xml.etree import ElementTree as ET\n",
    "import csv, re\n",
    "\n",
    "f = open('../INPUT_data/articles.csv')\n",
    "o = open('../OUTPUT_xml/articles.xml', 'w')\n",
    "\n",
    "csv_f = csv.reader(f)   \n",
    "data = []\n",
    "\n",
    "for row in csv_f: \n",
    "   data.append(row)\n",
    "f.close()\n",
    "\n",
    "\n",
    "###################################\n",
    "## WRITE DECLARATIONS AND BEGINNING OF THE XML FILE -adding more line breaks for readibility '+'\\n'+' ???-\n",
    "###################################\n",
    "o.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>'+'\\n'+'<knoraXmlImport:resources xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/knoraXmlImport/v1# ../p0112-roud-oeuvres-xml-schemas/p0112-roud-oeuvres.xsd\" xmlns=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\" xmlns:p0112-roud-oeuvres=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\">'+'\\n')\n",
    "\n",
    "\n",
    "\n",
    "biblio_number_new = 1000  ## starting point for counting biblioid that should be added because are not in the original\n",
    "    \n",
    "\n",
    "###################################\n",
    "## PREPARE CONTENT OF ELEMENTS AND ATTRIBUTES\n",
    "###################################\n",
    "for row in data[0:]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ## -----------------------> @id\n",
    "    biblio_number_new += 1    \n",
    "    if (row[0] != ''):\n",
    "        Publicationid = 'biblio_'+row[0] ## @id\n",
    "    else:\n",
    "        Publicationid = 'biblio_'+str(biblio_number_new)   ## increasing number, just to give it an id. Starts from 1000\n",
    "    \n",
    "      \n",
    "        \n",
    "        \n",
    "    \n",
    "    ## -----------------------> hasPublicationType\n",
    "    if ('Œuvre poétique' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-oeuvrePoetique'\n",
    "    if ('Périodique' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-propos'\n",
    "    ##if ('À propos de Roud' in row[1]):\n",
    "      ##  HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-journal'\n",
    "    if ('Traduction' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-traduction'\n",
    "    if ('Photographie' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-photo'\n",
    "    if ('Correspondance' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-correspondance'\n",
    "    if ('À propos de Roud' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-surRoud'\n",
    "    \n",
    "    \n",
    "    ## -----------------------> publicationHasTitle\n",
    "    PublicationHasTitle = row[3]  \n",
    "    \n",
    "    \n",
    "    ## -----------------------> isPublishedInPeriodical\n",
    "    periodicalTitle = row[4].replace('\"', '')  ## all this copied from transformation to periodical above\n",
    "    word_list = re.split(', |\\(|/', periodicalTitle) \n",
    "    word_list = word_list[0].replace(\"'\", ' ').replace(\",\", '').split()  \n",
    "    PeriodicalTarget = '_'.join(word_list) \n",
    "    \n",
    "    \n",
    "    ## -----------------------> publicationHasTitle\n",
    "    HasCollaborators = row[6]  \n",
    "    \n",
    "    \n",
    "    ## -----------------------> IsInPeriodicalIssue\n",
    "    IsInPeriodicalIssueVolume = row[7]\n",
    "    if (',' in row[7]):\n",
    "        IsInPeriodicalIssue_split = re.split(', ',row[7])\n",
    "        IsInPeriodicalIssue = IsInPeriodicalIssue_split[0]\n",
    "        IsInPeriodicalVolume = IsInPeriodicalIssue_split[1].replace('-', ' et ')\n",
    "    else:\n",
    "        IsInPeriodicalVolumeOnly = row[7].replace('-', ' et ')\n",
    "    \n",
    "    \n",
    "    ## -----------------------> publicationHasDate   \n",
    "    Date = row[10]\n",
    "    pattern = re.compile(\"\\d\\d\\d\\d-\\d\\d\\d\\d\")\n",
    "    if ('(' in Date):\n",
    "        Datedmy_split = re.split('-', Date)  ## split in day, month, year\n",
    "        Date1y = Datedmy_split[0]\n",
    "        Date1m = Datedmy_split[1]\n",
    "        Date12_split = re.split('\\(', Date)  ## split in date1 and date2\n",
    "        Date1 = Date12_split[0]\n",
    "        Date2 = Date12_split[1].replace('(', '').replace(')', '')\n",
    "        if len(Date1) > 7:             ## period includes year and month and days\n",
    "            if len(Date2) > 3:         ## period includes year and month and days (month and days are different)\n",
    "                PeriodMD = 'GREGORIAN:'+Date1+' CE:'+Date1y+Date2+' CE'  \n",
    "            else:                      ## period includes year and month and days (only days are different)     \n",
    "                PeriodD = 'GREGORIAN:'+Date1+' CE:'+Date1y+'-'+Date1m+Date2+' CE'  \n",
    "        else:                          ## period includes year and month\n",
    "            PeriodM = 'GREGORIAN:'+Date1+' CE:'+Date1y+Date2+' CE'\n",
    "    else:\n",
    "        if (pattern.match(Date)):\n",
    "            DateY_split = re.split('-', Date)\n",
    "            DateY1 = DateY_split[0]\n",
    "            DateY2 = DateY_split[1]\n",
    "            PeriodY = 'GREGORIAN:'+DateY1+' CE:'+DateY2+' CE'\n",
    "        else:\n",
    "            PublicationHasDate = 'GREGORIAN:'+Date+' CE'\n",
    "    \n",
    "    \n",
    "    ## -----------------------> periodicalArticleIsInPages\n",
    "    PeriodicalArticleIsInPages = row[11]  \n",
    "    \n",
    "    \n",
    "    ## -----------------------> publicationHasInternalComment\n",
    "    PublicationHasInternalComment = row[12]\n",
    "    \n",
    "    \n",
    "    ## -----------------------> PublicationIsTranscribed\n",
    "    PublicationIsTranscribed = row[13]\n",
    "    \n",
    "    \n",
    "    ## -----------------------> PublicationIsTranscribed\n",
    "    OriginalIsInCrlrArchive = row[16]\n",
    "  \n",
    "    \n",
    "    ## -----------------------> publicationHasAuthor\n",
    "    ArticleAuthor = row[2]\n",
    "    if (',' in ArticleAuthor):\n",
    "        ArticleAuthor_split = re.split(', ', ArticleAuthor)\n",
    "        if (' ' in ArticleAuthor_split[0]):\n",
    "            ArticlesSurname = ArticleAuthor_split[0].partition(' ')[0]\n",
    "            ArticlesName = ArticleAuthor_split[0].partition(' ')[2]\n",
    "            ArticlesSurnameSecond = ArticleAuthor_split[1].partition(' ')[0]\n",
    "            ArticlesNameSecond = ArticleAuthor_split[1].partition(' ')[2]\n",
    "            with open(\"../INPUT_data/authors_with_id.csv\", 'r') as authors_with_id:   \n",
    "                csv_authors = csv.reader(authors_with_id)\n",
    "                ## AuthorTarget = [row[2] for row in csv_authors if ArticlesSurname in row[0]]  this creates list, while I want item\n",
    "                for row in csv_authors:\n",
    "                    if (ArticlesSurname == row[0] and ArticlesName == row[1]):\n",
    "                        AuthorTarget = row[2]\n",
    "                    if (ArticlesSurnameSecond == row[0] and ArticlesNameSecond == row[1]):\n",
    "                        AuthorTargetSecond = row[2]\n",
    "        else:\n",
    "            ArticlesSurname = ArticleAuthor_split[0]\n",
    "            ArticlesSurnameSecond = ArticleAuthor_split[1].partition(' ')[0]\n",
    "            ArticlesNameSecond = ArticleAuthor_split[1].partition(' ')[2]\n",
    "            with open(\"../INPUT_data/authors_with_id.csv\", 'r') as authors_with_id:   \n",
    "                csv_authors = csv.reader(authors_with_id)\n",
    "                ## AuthorTarget = [row[2] for row in csv_authors if ArticlesSurname in row[0]]  this creates list, while I want item\n",
    "                for row in csv_authors:\n",
    "                    if (ArticlesSurname == row[0]):\n",
    "                        AuthorTarget = row[2]\n",
    "                    if (ArticlesSurnameSecond == row[0] and ArticlesNameSecond == row[1]):\n",
    "                        AuthorTargetSecond = row[2]\n",
    "    else:\n",
    "        if (' ' in ArticleAuthor):\n",
    "            ArticlesSurname = ArticleAuthor.partition(' ')[0]\n",
    "            ArticlesName = ArticleAuthor.partition(' ')[2]\n",
    "            with open(\"../INPUT_data/authors_with_id.csv\", 'r') as authors_with_id:   \n",
    "                csv_authors = csv.reader(authors_with_id)\n",
    "                ## AuthorTarget = [row[2] for row in csv_authors if ArticlesSurname in row[0]]  this creates list, while I want item\n",
    "                for row in csv_authors:\n",
    "                    if (ArticlesSurname == row[0] and ArticlesName == row[1]):\n",
    "                        AuthorTargetSingle = row[2]\n",
    "        else:\n",
    "            ArticlesSurname = ArticleAuthor\n",
    "            with open(\"../INPUT_data/authors_with_id.csv\", 'r') as authors_with_id:   \n",
    "                csv_authors = csv.reader(authors_with_id)\n",
    "                ## AuthorTarget = [row[2] for row in csv_authors if ArticlesSurname in row[0]]  this creates list, while I want item\n",
    "                for row in csv_authors:\n",
    "                    if (ArticlesSurname == row[0]):\n",
    "                        AuthorTargetSingle = row[2]  \n",
    "        \n",
    "    \n",
    "    \n",
    "    ## -----------------------> label\n",
    "    if (ArticleAuthor != '' and PublicationHasTitle != '' and PeriodicalTarget != '' and Date != ''):\n",
    "        PeriodicalArticleLabelComplete = \"pub_\"+ArticleAuthor+' ___ '+PublicationHasTitle+' ___ '+PeriodicalTarget+' ___ '+Date\n",
    "    else:\n",
    "        if (ArticleAuthor != '' and PublicationHasTitle != '' and PeriodicalTarget != ''):\n",
    "            PeriodicalArticleLabelComplete = \"pub_\"+ArticleAuthor+' ___ '+PublicationHasTitle+' ___ '+PeriodicalTarget\n",
    "        else:\n",
    "            if (ArticleAuthor != '' and PublicationHasTitle != '' and Date != ''):\n",
    "                PeriodicalArticleLabelComplete = \"pub_\"+ArticleAuthor+' ___ '+PublicationHasTitle+' ___ '+Date\n",
    "            else:\n",
    "                if (ArticleAuthor != '' and PeriodicalTarget != '' and Date != ''):\n",
    "                    PeriodicalArticleLabelComplete = \"pub_\"+ArticleAuthor+' ___ '+PeriodicalTarget+' ___ '+Date\n",
    "                else:\n",
    "                    if (PublicationHasTitle != '' and PeriodicalTarget != '' and Date != ''):\n",
    "                        PeriodicalArticleLabelComplete = \"pub_\"+PublicationHasTitle+' ___ '+PeriodicalTarget+' ___ '+Date\n",
    "\n",
    "    PeriodicalArticleLabel = re.sub(r\"\\(([^\\)]+)\\)\", \"\", PeriodicalArticleLabelComplete)\n",
    "    \n",
    "    \n",
    "    \n",
    "                \n",
    "                \n",
    "    \n",
    "    ###################################\n",
    "    #### REGISTERING NAMESPACES\n",
    "    ###################################\n",
    "    NS_ROUD = \"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" \n",
    "    NS_KNORAIMPORT = \"http://api.knora.org/ontology/knoraXmlImport/v1#\"\n",
    "    ET.register_namespace(\"p0112-roud-oeuvres\", NS_ROUD)\n",
    "    ET.register_namespace(\"knoraXmlImport\", NS_KNORAIMPORT)\n",
    "\n",
    "    \n",
    "    ###################################\n",
    "    ## DEFINE ELEMENTS WITH NS\n",
    "    ###################################\n",
    "    PeriodicalArticleNS = ET.QName(NS_ROUD, \"PeriodicalArticle\")\n",
    "    labelNS = ET.QName(NS_KNORAIMPORT, \"label\")\n",
    "    hasPublicationTypeNS = ET.QName(NS_ROUD, \"hasPublicationType\")\n",
    "    publicationHasAuthorNS = ET.QName(NS_ROUD, \"publicationHasAuthor\")\n",
    "    AuthorNS = ET.QName(NS_ROUD, \"Author\")\n",
    "    publicationHasTitleNS = ET.QName(NS_ROUD, \"publicationHasTitle\")\n",
    "    isPublishedInPeriodicalNS = ET.QName(NS_ROUD, \"isPublishedInPeriodical\")\n",
    "    PeriodicalNS = ET.QName(NS_ROUD, \"Periodical\")\n",
    "    hasCollaboratorsNS = ET.QName(NS_ROUD, \"hasCollaborators\")\n",
    "    isInPeriodicalIssueNS = ET.QName(NS_ROUD, \"isInPeriodicalIssue\")\n",
    "    isInPeriodicalVolumeNS = ET.QName(NS_ROUD, \"isInPeriodicalVolume\")\n",
    "    publicationHasDateNS = ET.QName(NS_ROUD, \"publicationHasDate\")\n",
    "    periodicalArticleIsInPagesNS = ET.QName(NS_ROUD, \"periodicalArticleIsInPages\")\n",
    "    publicationHasInternalCommentNS = ET.QName(NS_ROUD, \"publicationHasInternalComment\")\n",
    "    publicationIsTranscribedNS = ET.QName(NS_ROUD, \"publicationIsTranscribed\")\n",
    "    originalIsInCrlrArchiveNS = ET.QName(NS_ROUD, \"originalIsInCrlrArchive\")\n",
    "    \n",
    "    \n",
    "    ###################################\n",
    "    ## CREATE ELEMENTS AND ATTRIBUTES (AS PREVIOUSLY DEFINED WITH NS) AND ASSIGN THEM CONTENT\n",
    "    ###################################\n",
    "    PeriodicalArticle = ET.Element(PeriodicalArticleNS, attrib={'id':Publicationid}) \n",
    "    \n",
    "    label = ET.SubElement(PeriodicalArticle, labelNS)\n",
    "    label.text = PeriodicalArticleLabel\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> hasCollaborators\n",
    "    if (HasCollaborators != ''):\n",
    "        hasCollaborators = ET.SubElement(PeriodicalArticle, hasCollaboratorsNS, attrib={'knoraType':'richtext_value'})\n",
    "        hasCollaborators.text = HasCollaborators\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> hasPublicationType\n",
    "    hasPublicationType = ET.SubElement(PeriodicalArticle, hasPublicationTypeNS, attrib={'knoraType':'hlist_value'})\n",
    "    hasPublicationType.text = HasPublicationType  ## use variable defined with name of the publisher corresponding to second row\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> isInPeriodicalVolume  and  isInPeriodicalIssue\n",
    "    if (IsInPeriodicalIssueVolume != '' and IsInPeriodicalVolumeOnly == ''):\n",
    "        isInPeriodicalIssue = ET.SubElement(PeriodicalArticle, isInPeriodicalIssueNS, attrib={'knoraType':'richtext_value'})\n",
    "        isInPeriodicalIssue.text = IsInPeriodicalIssue\n",
    "        isInPeriodicalVolume = ET.SubElement(PeriodicalArticle, isInPeriodicalVolumeNS, attrib={'knoraType':'richtext_value'})\n",
    "        isInPeriodicalVolume.text = IsInPeriodicalVolume\n",
    "    else:   \n",
    "        if (IsInPeriodicalIssueVolume != ''):\n",
    "            isInPeriodicalVolume = ET.SubElement(PeriodicalArticle, isInPeriodicalVolumeNS, attrib={'knoraType':'richtext_value'})\n",
    "            isInPeriodicalVolume.text = IsInPeriodicalVolumeOnly\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> isPublishedInPeriodical\n",
    "    isPublishedInPeriodical = ET.SubElement(PeriodicalArticle, isPublishedInPeriodicalNS)\n",
    "    Periodical = ET.SubElement(isPublishedInPeriodical, PeriodicalNS, attrib={'knoraType':'link_value', 'linkType':'ref', 'target':PeriodicalTarget})\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> OriginalIsInCrlrArchive\n",
    "    if (OriginalIsInCrlrArchive != ''):\n",
    "        originalIsInCrlrArchive = ET.SubElement(PeriodicalArticle, originalIsInCrlrArchiveNS, attrib={'knoraType':'richtext_value'})\n",
    "        originalIsInCrlrArchive.text = OriginalIsInCrlrArchive\n",
    "        \n",
    "    \n",
    "    ## -----------------------------> periodicalArticleIsInPages\n",
    "    if (PeriodicalArticleIsInPages != ''):\n",
    "        periodicalArticleIsInPages = ET.SubElement(PeriodicalArticle, periodicalArticleIsInPagesNS, attrib={'knoraType':'richtext_value'})\n",
    "        periodicalArticleIsInPages.text = PeriodicalArticleIsInPages\n",
    "        \n",
    "    \n",
    "    \n",
    "    ## -----------------------------> publicationHasAuthor\n",
    "    if (ArticleAuthor != ''):\n",
    "        if (',') in ArticleAuthor:\n",
    "            publicationHasAuthor = ET.SubElement(PeriodicalArticle, publicationHasAuthorNS)\n",
    "            Author = ET.SubElement(publicationHasAuthor, AuthorNS, attrib={'knoraType':'link_value', 'linkType':'ref', 'target':AuthorTarget})\n",
    "            publicationHasAuthor = ET.SubElement(PeriodicalArticle, publicationHasAuthorNS)\n",
    "            Author = ET.SubElement(publicationHasAuthor, AuthorNS, attrib={'knoraType':'link_value', 'linkType':'ref', 'target':AuthorTargetSecond})\n",
    "        else:\n",
    "            publicationHasAuthor = ET.SubElement(PeriodicalArticle, publicationHasAuthorNS)\n",
    "            Author = ET.SubElement(publicationHasAuthor, AuthorNS, attrib={'knoraType':'link_value', 'linkType':'ref', 'target':AuthorTargetSingle})\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## -----------------------------> publicationHasDate\n",
    "    if (Date != ''):\n",
    "        publicationHasDate = ET.SubElement(PeriodicalArticle, publicationHasDateNS, attrib={'knoraType':'date_value'})\n",
    "    \n",
    "    if ('(' in Date):\n",
    "        if len(Date1) > 7:\n",
    "            if len(Date2) > 3:   \n",
    "                publicationHasDate.text = PeriodMD\n",
    "            else:\n",
    "                publicationHasDate.text = PeriodD\n",
    "        else:\n",
    "            publicationHasDate.text = PeriodM\n",
    "    else:\n",
    "        if (pattern.match(Date)):\n",
    "            publicationHasDate.text = PeriodY\n",
    "        else:\n",
    "            if (Date != ''):\n",
    "                publicationHasDate.text = PublicationHasDate\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> publicationHasInternalComment\n",
    "    if (PublicationHasInternalComment != ''):\n",
    "        publicationHasInternalComment = ET.SubElement(PeriodicalArticle, publicationHasInternalCommentNS, attrib={'knoraType':'richtext_value'})\n",
    "        publicationHasInternalComment.text = PublicationHasInternalComment\n",
    "        \n",
    "    \n",
    "    ## -----------------------------> publicationHasTitle\n",
    "    publicationHasTitle = ET.SubElement(PeriodicalArticle, publicationHasTitleNS, attrib={'knoraType':'richtext_value'})\n",
    "    publicationHasTitle.text = PublicationHasTitle\n",
    "    \n",
    "    \n",
    "     ## -----------------------------> publicationIsTranscribed\n",
    "    if (PublicationIsTranscribed != ''):\n",
    "        publicationIsTranscribed = ET.SubElement(PeriodicalArticle, publicationIsTranscribedNS, attrib={'knoraType':'richtext_value'})\n",
    "        publicationIsTranscribed.text = PublicationIsTranscribed\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    tree = ET.tostring(PeriodicalArticle, encoding=\"unicode\")\n",
    "    o.write('\\n''\\n'+ tree)\n",
    "\n",
    "## WRITE END OF THE XML FILE\n",
    "with o:  ## this is to append the text, if just write o.write does not work here (why??)\n",
    "    o.write('\\n'+'</knoraXmlImport:resources>')\n",
    "\n",
    "o.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### CREATE XML FROM CSV (BOOKS)\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "from xml.etree import ElementTree as ET\n",
    "import csv, re\n",
    "\n",
    "f = open('../INPUT_data/books.csv')\n",
    "o = open('../OUTPUT_xml/books.xml', 'w')\n",
    "\n",
    "csv_f = csv.reader(f)   \n",
    "data = []\n",
    "\n",
    "for row in csv_f: \n",
    "   data.append(row)\n",
    "f.close()\n",
    "\n",
    "\n",
    "## SI [0] id, [1] type, [2] author, [3] title, [6] collaborateurs, [8] placepub, [9] namepub, \n",
    "## SI [10] date, [11] pages, [12] comm interne, [13] Retranscrit, [15] digitized, [16] dans fonds CRLR  ##\n",
    "## NO [4] title_pub, [5] illustré par, [7] numéro, [14] website interest  ##\n",
    "\n",
    "\n",
    "\n",
    "###################################\n",
    "## WRITE DECLARATIONS AND BEGINNING OF THE XML FILE -adding more line breaks for readibility '+'\\n'+' ???-\n",
    "###################################\n",
    "o.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>'+'\\n'+'<knoraXmlImport:resources xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/knoraXmlImport/v1# ../p0112-roud-oeuvres-xml-schemas/p0112-roud-oeuvres.xsd\" xmlns=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\" xmlns:p0112-roud-oeuvres=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\">'+'\\n')\n",
    "\n",
    "\n",
    "\n",
    "biblio_number_new = 2000  ## starting point for counting biblioid that should be added because are not in the original\n",
    "    \n",
    "\n",
    "###################################\n",
    "## PREPARE CONTENT OF ELEMENTS AND ATTRIBUTES\n",
    "###################################\n",
    "for row in data[0:]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ## -----------------------> @id\n",
    "    biblio_number_new += 1    \n",
    "    if (row[0] != ''):\n",
    "        Publicationid = 'biblio_'+row[0] ## @id\n",
    "    else:\n",
    "        Publicationid = 'biblio_'+str(biblio_number_new)   ## increasing number, just to give it an id. Starts from 1000\n",
    "    \n",
    "      \n",
    "        \n",
    "        \n",
    "    \n",
    "    ## -----------------------> hasPublicationType\n",
    "    if ('Œuvre poétique' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-oeuvrePoetique'\n",
    "    if ('Périodique' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-propos'\n",
    "    ##if ('À propos de Roud' in row[1]):\n",
    "      ##  HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-journal'\n",
    "    if ('Traduction' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-traduction'\n",
    "    if ('Photographie' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-photo'\n",
    "    if ('Correspondance' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-correspondance'\n",
    "    if ('À propos de Roud' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-surRoud'\n",
    "    \n",
    "    \n",
    "    ## -----------------------> publicationHasTitle\n",
    "    PublicationHasTitle = row[3]  \n",
    "    \n",
    "    \n",
    "    ## -----------------------> publicationHasCollaborators\n",
    "    HasCollaborators = row[6]  \n",
    "    \n",
    "    \n",
    "    ## -----------------------> hasPublisher (PublisherTarget)\n",
    "    publisherName = row[9]\n",
    "    word_list = publisherName.replace(\"'\", ' ') ## replace accent with space\n",
    "    word_list = word_list.replace(\",\", '').split()  ## replace comma with nothing and split words\n",
    "    PublisherTarget = '_'.join(word_list)\n",
    "    \n",
    "    \n",
    "    ## -----------------------> publicationHasDate   \n",
    "    Date = row[10]\n",
    "    pattern = re.compile(\"\\d\\d\\d\\d-\\d\\d\\d\\d\")\n",
    "    if ('(' in Date):\n",
    "        Datedmy_split = re.split('-', Date)  ## split in day, month, year\n",
    "        Date1y = Datedmy_split[0]\n",
    "        Date1m = Datedmy_split[1]\n",
    "        Date12_split = re.split('\\(', Date)  ## split in date1 and date2\n",
    "        Date1 = Date12_split[0]\n",
    "        Date2 = Date12_split[1].replace('(', '').replace(')', '')\n",
    "        if len(Date1) > 7:             ## period includes year and month and days\n",
    "            if len(Date2) > 3:         ## period includes year and month and days (month and days are different)\n",
    "                PeriodMD = 'GREGORIAN:'+Date1+' CE:'+Date1y+Date2+' CE'  \n",
    "            else:                      ## period includes year and month and days (only days are different)     \n",
    "                PeriodD = 'GREGORIAN:'+Date1+' CE:'+Date1y+'-'+Date1m+Date2+' CE'  \n",
    "        else:                          ## period includes year and month\n",
    "            PeriodM = 'GREGORIAN:'+Date1+' CE:'+Date1y+Date2+' CE'\n",
    "    else:\n",
    "        if (pattern.match(Date)):\n",
    "            DateY_split = re.split('-', Date)\n",
    "            DateY1 = DateY_split[0]\n",
    "            DateY2 = DateY_split[1]\n",
    "            PeriodY = 'GREGORIAN:'+DateY1+' CE:'+DateY2+' CE'\n",
    "        else:\n",
    "            PublicationHasDate = 'GREGORIAN:'+Date+' CE'\n",
    "    \n",
    "    \n",
    "    ## -----------------------> bookHasSpecificPages\n",
    "    BookHasSpecificPages = row[11]  \n",
    "    \n",
    "    \n",
    "    ## -----------------------> publicationHasInternalComment\n",
    "    PublicationHasInternalComment = row[12]\n",
    "    \n",
    "    \n",
    "    ## -----------------------> PublicationIsTranscribed\n",
    "    PublicationIsTranscribed = row[13]\n",
    "    \n",
    "    \n",
    "    ## -----------------------> PublicationIsTranscribed\n",
    "    OriginalIsInCrlrArchive = row[16]\n",
    "  \n",
    "    \n",
    "    ## -----------------------> publicationHasAuthor\n",
    "    ArticleAuthor = row[2]\n",
    "    if (',' in ArticleAuthor):\n",
    "        ArticleAuthor_split = re.split(', ', ArticleAuthor)\n",
    "        if (' ' in ArticleAuthor_split[0]):\n",
    "            ArticlesSurname = ArticleAuthor_split[0].partition(' ')[0]\n",
    "            ArticlesName = ArticleAuthor_split[0].partition(' ')[2]\n",
    "            ArticlesSurnameSecond = ArticleAuthor_split[1].partition(' ')[0]\n",
    "            ArticlesNameSecond = ArticleAuthor_split[1].partition(' ')[2]\n",
    "            with open(\"../INPUT_data/authors_with_id.csv\", 'r') as authors_with_id:   \n",
    "                csv_authors = csv.reader(authors_with_id)\n",
    "                ## AuthorTarget = [row[2] for row in csv_authors if ArticlesSurname in row[0]]  this creates list, while I want item\n",
    "                for row in csv_authors:\n",
    "                    if (ArticlesSurname == row[0] and ArticlesName == row[1]):\n",
    "                        AuthorTarget = row[2]\n",
    "                    if (ArticlesSurnameSecond == row[0] and ArticlesNameSecond == row[1]):\n",
    "                        AuthorTargetSecond = row[2]\n",
    "        else:\n",
    "            ArticlesSurname = ArticleAuthor_split[0]\n",
    "            ArticlesSurnameSecond = ArticleAuthor_split[1].partition(' ')[0]\n",
    "            ArticlesNameSecond = ArticleAuthor_split[1].partition(' ')[2]\n",
    "            with open(\"../INPUT_data/authors_with_id.csv\", 'r') as authors_with_id:   \n",
    "                csv_authors = csv.reader(authors_with_id)\n",
    "                ## AuthorTarget = [row[2] for row in csv_authors if ArticlesSurname in row[0]]  this creates list, while I want item\n",
    "                for row in csv_authors:\n",
    "                    if (ArticlesSurname == row[0]):\n",
    "                        AuthorTarget = row[2]\n",
    "                    if (ArticlesSurnameSecond == row[0] and ArticlesNameSecond == row[1]):\n",
    "                        AuthorTargetSecond = row[2]\n",
    "    else:\n",
    "        if (' ' in ArticleAuthor):\n",
    "            ArticlesSurname = ArticleAuthor.partition(' ')[0]\n",
    "            ArticlesName = ArticleAuthor.partition(' ')[2]\n",
    "            with open(\"../INPUT_data/authors_with_id.csv\", 'r') as authors_with_id:   \n",
    "                csv_authors = csv.reader(authors_with_id)\n",
    "                ## AuthorTarget = [row[2] for row in csv_authors if ArticlesSurname in row[0]]  this creates list, while I want item\n",
    "                for row in csv_authors:\n",
    "                    if (ArticlesSurname == row[0] and ArticlesName == row[1]):\n",
    "                        AuthorTargetSingle = row[2]\n",
    "        else:\n",
    "            ArticlesSurname = ArticleAuthor\n",
    "            with open(\"../INPUT_data/authors_with_id.csv\", 'r') as authors_with_id:   \n",
    "                csv_authors = csv.reader(authors_with_id)\n",
    "                ## AuthorTarget = [row[2] for row in csv_authors if ArticlesSurname in row[0]]  this creates list, while I want item\n",
    "                for row in csv_authors:\n",
    "                    if (ArticlesSurname == row[0]):\n",
    "                        AuthorTargetSingle = row[2]  \n",
    "                        \n",
    "                    \n",
    "    ## -----------------------> label\n",
    "    if (ArticleAuthor != '' and PublicationHasTitle != '' and Date != ''):\n",
    "        BookLabelComplete = \"pub_\"+ArticleAuthor+' ___ '+PublicationHasTitle+' ___ '+Date\n",
    "    else:\n",
    "        if (ArticleAuthor != '' and PublicationHasTitle != ''):\n",
    "            BookLabelComplete = \"pub_\"+ArticleAuthor+' ___ '+PublicationHasTitle\n",
    "        else:\n",
    "            if (ArticleAuthor != '' and Date != ''):\n",
    "                BookLabelComplete = \"pub_\"+ArticleAuthor+Date\n",
    "            else:\n",
    "                if (PublicationHasTitle != '' and Date != ''):\n",
    "                    BookLabelComplete = \"pub_\"+PublicationHasTitle+' ___ '+Date\n",
    "\n",
    "    BookLabel = re.sub(r\"\\(([^\\)]+)\\)\", \"\", BookLabelComplete)\n",
    "\n",
    "    \n",
    "                \n",
    "                \n",
    "    \n",
    "    ###################################\n",
    "    #### REGISTERING NAMESPACES\n",
    "    ###################################\n",
    "    NS_ROUD = \"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" \n",
    "    NS_KNORAIMPORT = \"http://api.knora.org/ontology/knoraXmlImport/v1#\"\n",
    "    ET.register_namespace(\"p0112-roud-oeuvres\", NS_ROUD)\n",
    "    ET.register_namespace(\"knoraXmlImport\", NS_KNORAIMPORT)\n",
    "\n",
    "    \n",
    "    ###################################\n",
    "    ## DEFINE ELEMENTS WITH NS\n",
    "    ###################################\n",
    "    BookNS = ET.QName(NS_ROUD, \"Book\")\n",
    "    labelNS = ET.QName(NS_KNORAIMPORT, \"label\")\n",
    "    bookHasSpecificPagesNS = ET.QName(NS_ROUD, \"bookHasSpecificPages\")\n",
    "    hasPublicationTypeNS = ET.QName(NS_ROUD, \"hasPublicationType\")\n",
    "    hasPublisherNS = ET.QName(NS_ROUD, \"hasPublisher\")\n",
    "    PublisherNS = ET.QName(NS_ROUD, \"Publisher\")\n",
    "    publicationHasAuthorNS = ET.QName(NS_ROUD, \"publicationHasAuthor\")\n",
    "    AuthorNS = ET.QName(NS_ROUD, \"Author\")\n",
    "    publicationHasTitleNS = ET.QName(NS_ROUD, \"publicationHasTitle\")\n",
    "    hasCollaboratorsNS = ET.QName(NS_ROUD, \"hasCollaborators\")\n",
    "    publicationHasDateNS = ET.QName(NS_ROUD, \"publicationHasDate\")\n",
    "    publicationHasInternalCommentNS = ET.QName(NS_ROUD, \"publicationHasInternalComment\")\n",
    "    publicationIsTranscribedNS = ET.QName(NS_ROUD, \"publicationIsTranscribed\")\n",
    "    originalIsInCrlrArchiveNS = ET.QName(NS_ROUD, \"originalIsInCrlrArchive\")\n",
    "    \n",
    "    \n",
    "    ###################################\n",
    "    ## CREATE ELEMENTS AND ATTRIBUTES (AS PREVIOUSLY DEFINED WITH NS) AND ASSIGN THEM CONTENT\n",
    "    ###################################\n",
    "    \n",
    "    Book = ET.Element(BookNS, attrib={'id':Publicationid}) \n",
    "    \n",
    "    label = ET.SubElement(Book, labelNS)\n",
    "    label.text = BookLabel\n",
    "    \n",
    "    ## -----------------------------> bookHasSpecificPages\n",
    "    if (BookHasSpecificPages!= ''):\n",
    "        bookHasSpecificPages = ET.SubElement(Book, bookHasSpecificPagesNS, attrib={'knoraType':'richtext_value'})\n",
    "        bookHasSpecificPages.text = BookHasSpecificPages\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> hasCollaborators\n",
    "    if (HasCollaborators != ''):\n",
    "        hasCollaborators = ET.SubElement(Book, hasCollaboratorsNS, attrib={'knoraType':'richtext_value'})\n",
    "        hasCollaborators.text = HasCollaborators\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> hasPublicationType\n",
    "    hasPublicationType = ET.SubElement(Book, hasPublicationTypeNS, attrib={'knoraType':'hlist_value'})\n",
    "    hasPublicationType.text = HasPublicationType  ## use variable defined with name of the publisher corresponding to second row\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> hasPublisher\n",
    "    if (publisherName != ''):\n",
    "        hasPublisher = ET.SubElement(Book, hasPublisherNS)\n",
    "        Publisher = ET.SubElement(hasPublisher, PublisherNS, attrib={'knoraType':'link_value', 'linkType':'ref', 'target':PublisherTarget})\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## -----------------------------> OriginalIsInCrlrArchive\n",
    "    if (OriginalIsInCrlrArchive != ''):\n",
    "        originalIsInCrlrArchive = ET.SubElement(Book, originalIsInCrlrArchiveNS, attrib={'knoraType':'richtext_value'})\n",
    "        originalIsInCrlrArchive.text = OriginalIsInCrlrArchive\n",
    "        \n",
    "    \n",
    "    ## -----------------------------> publicationHasAuthor\n",
    "    if (',') in ArticleAuthor:\n",
    "        publicationHasAuthor = ET.SubElement(Book, publicationHasAuthorNS)\n",
    "        Author = ET.SubElement(publicationHasAuthor, AuthorNS, attrib={'knoraType':'link_value', 'linkType':'ref', 'target':AuthorTarget})\n",
    "        publicationHasAuthor = ET.SubElement(Book, publicationHasAuthorNS)\n",
    "        Author = ET.SubElement(publicationHasAuthor, AuthorNS, attrib={'knoraType':'link_value', 'linkType':'ref', 'target':AuthorTargetSecond})\n",
    "    else:\n",
    "        publicationHasAuthor = ET.SubElement(Book, publicationHasAuthorNS)\n",
    "        Author = ET.SubElement(publicationHasAuthor, AuthorNS, attrib={'knoraType':'link_value', 'linkType':'ref', 'target':AuthorTargetSingle})\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## -----------------------------> publicationHasDate\n",
    "    if (Date != ''):\n",
    "        publicationHasDate = ET.SubElement(Book, publicationHasDateNS, attrib={'knoraType':'date_value'})\n",
    "    \n",
    "    if ('(' in Date):\n",
    "        if len(Date1) > 7:\n",
    "            if len(Date2) > 3:   \n",
    "                publicationHasDate.text = PeriodMD\n",
    "            else:\n",
    "                publicationHasDate.text = PeriodD\n",
    "        else:\n",
    "            publicationHasDate.text = PeriodM\n",
    "    else:\n",
    "        if (pattern.match(Date)):\n",
    "            publicationHasDate.text = PeriodY\n",
    "        else:\n",
    "            if (Date != ''):\n",
    "                publicationHasDate.text = PublicationHasDate\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> publicationHasInternalComment\n",
    "    if (PublicationHasInternalComment != ''):\n",
    "        publicationHasInternalComment = ET.SubElement(Book, publicationHasInternalCommentNS, attrib={'knoraType':'richtext_value'})\n",
    "        publicationHasInternalComment.text = PublicationHasInternalComment\n",
    "        \n",
    "    \n",
    "    ## -----------------------------> publicationHasTitle\n",
    "    publicationHasTitle = ET.SubElement(Book, publicationHasTitleNS, attrib={'knoraType':'richtext_value'})\n",
    "    publicationHasTitle.text = PublicationHasTitle\n",
    "    \n",
    "    \n",
    "     ## -----------------------------> publicationIsTranscribed\n",
    "    if (PublicationIsTranscribed != ''):\n",
    "        publicationIsTranscribed = ET.SubElement(Book, publicationIsTranscribedNS, attrib={'knoraType':'richtext_value'})\n",
    "        publicationIsTranscribed.text = PublicationIsTranscribed\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    tree = ET.tostring(Book, encoding=\"unicode\")\n",
    "    o.write('\\n''\\n'+ tree)\n",
    "\n",
    "## WRITE END OF THE XML FILE\n",
    "with o:  ## this is to append the text, if just write o.write does not work here (why??)\n",
    "    o.write('\\n'+'</knoraXmlImport:resources>')\n",
    "\n",
    "o.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### CREATE XML FROM CSV (BOOK SECTION)\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "from xml.etree import ElementTree as ET\n",
    "import csv, re\n",
    "\n",
    "f = open('../INPUT_data/booksections.csv')\n",
    "o = open('../OUTPUT_xml/booksections.xml', 'w')\n",
    "\n",
    "csv_f = csv.reader(f)   \n",
    "data = []\n",
    "\n",
    "for row in csv_f: \n",
    "   data.append(row)\n",
    "f.close()\n",
    "\n",
    "\n",
    "## SI [0] id, [1] type, [2] author, [3] title, [4] title_pub, [6] collaborateurs, [7] volume, [8] placepub, [9] namepub, \n",
    "## SI [10] date, [11] pages, [12] comm interne, [13] Retranscrit, [15] digitized, [16] dans fonds CRLR  ##\n",
    "## NO [5] illustré par, [14] website interest  ##\n",
    "\n",
    "\n",
    "\n",
    "###################################\n",
    "## WRITE DECLARATIONS AND BEGINNING OF THE XML FILE -adding more line breaks for readibility '+'\\n'+' ???-\n",
    "###################################\n",
    "o.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>'+'\\n'+'<knoraXmlImport:resources xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/knoraXmlImport/v1# ../p0112-roud-oeuvres-xml-schemas/p0112-roud-oeuvres.xsd\" xmlns=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\" xmlns:p0112-roud-oeuvres=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\">'+'\\n')\n",
    "\n",
    "\n",
    "\n",
    "biblio_number_new = 3000  ## starting point for counting biblioid that should be added because are not in the original\n",
    "    \n",
    "\n",
    "###################################\n",
    "## PREPARE CONTENT OF ELEMENTS AND ATTRIBUTES\n",
    "###################################\n",
    "for row in data[0:]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ## -----------------------> @id\n",
    "    biblio_number_new += 1    \n",
    "    if (row[0] != ''):\n",
    "        Publicationid = 'biblio_'+row[0] ## @id\n",
    "    else:\n",
    "        Publicationid = 'biblio_'+str(biblio_number_new)   ## increasing number, just to give it an id. Starts from 1000\n",
    "    \n",
    "      \n",
    "        \n",
    "        \n",
    "    \n",
    "    ## -----------------------> hasPublicationType\n",
    "    if ('Œuvre poétique' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-oeuvrePoetique'\n",
    "    if ('Périodique' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-propos'\n",
    "    ##if ('À propos de Roud' in row[1]):\n",
    "      ##  HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-journal'\n",
    "    if ('Traduction' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-traduction'\n",
    "    if ('Photographie' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-photo'\n",
    "    if ('Correspondance' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-correspondance'\n",
    "    if ('À propos de Roud' in row[1]):\n",
    "        HasPublicationType = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasPublicationType-surRoud'\n",
    "    \n",
    "    \n",
    "    ## -----------------------> publicationHasTitle\n",
    "    PublicationHasTitle = row[3]  \n",
    "    \n",
    "    \n",
    "    ## -----------------------> bookSectionIsPartOf\n",
    "    BookSectionIsPartOf = row[4]  \n",
    "    \n",
    "    \n",
    "    ## -----------------------> publicationHasCollaborators\n",
    "    HasCollaborators = row[6]  \n",
    "    \n",
    "    ## -----------------------> isInBookVolume\n",
    "    IsInBookVolume = row[7]  \n",
    "    \n",
    "    \n",
    "    ## -----------------------> hasPublisher (PublisherTarget)\n",
    "    publisherName = row[9]\n",
    "    word_list = publisherName.replace(\"'\", ' ') ## replace accent with space\n",
    "    word_list = word_list.replace(\",\", '').split()  ## replace comma with nothing and split words\n",
    "    PublisherTarget = '_'.join(word_list)\n",
    "    \n",
    "    \n",
    "    ## -----------------------> publicationHasDate   \n",
    "    Date = row[10]\n",
    "    pattern = re.compile(\"\\d\\d\\d\\d-\\d\\d\\d\\d\")\n",
    "    if ('(' in Date):\n",
    "        Datedmy_split = re.split('-', Date)  ## split in day, month, year\n",
    "        Date1y = Datedmy_split[0]\n",
    "        Date1m = Datedmy_split[1]\n",
    "        Date12_split = re.split('\\(', Date)  ## split in date1 and date2\n",
    "        Date1 = Date12_split[0]\n",
    "        Date2 = Date12_split[1].replace('(', '').replace(')', '')\n",
    "        if len(Date1) > 7:             ## period includes year and month and days\n",
    "            if len(Date2) > 3:         ## period includes year and month and days (month and days are different)\n",
    "                PeriodMD = 'GREGORIAN:'+Date1+' CE:'+Date1y+Date2+' CE'  \n",
    "            else:                      ## period includes year and month and days (only days are different)     \n",
    "                PeriodD = 'GREGORIAN:'+Date1+' CE:'+Date1y+'-'+Date1m+Date2+' CE'  \n",
    "        else:                          ## period includes year and month\n",
    "            PeriodM = 'GREGORIAN:'+Date1+' CE:'+Date1y+Date2+' CE'\n",
    "    else:\n",
    "        if (pattern.match(Date)):\n",
    "            DateY_split = re.split('-', Date)\n",
    "            DateY1 = DateY_split[0]\n",
    "            DateY2 = DateY_split[1]\n",
    "            PeriodY = 'GREGORIAN:'+DateY1+' CE:'+DateY2+' CE'\n",
    "        else:\n",
    "            PublicationHasDate = 'GREGORIAN:'+Date+' CE'\n",
    "    \n",
    "    \n",
    "    ## -----------------------> bookSectionIsInPages\n",
    "    BookSectionIsInPages = row[11]  \n",
    "    \n",
    "    \n",
    "    ## -----------------------> publicationHasInternalComment\n",
    "    PublicationHasInternalComment = row[12]\n",
    "    \n",
    "    \n",
    "    ## -----------------------> PublicationIsTranscribed\n",
    "    PublicationIsTranscribed = row[13]\n",
    "    \n",
    "    \n",
    "    ## -----------------------> PublicationIsTranscribed\n",
    "    OriginalIsInCrlrArchive = row[16]\n",
    "  \n",
    "    \n",
    "    ## -----------------------> publicationHasAuthor\n",
    "    ArticleAuthor = row[2]\n",
    "    if (',' in ArticleAuthor):\n",
    "        ArticleAuthor_split = re.split(', ', ArticleAuthor)\n",
    "        if (' ' in ArticleAuthor_split[0]):\n",
    "            ArticlesSurname = ArticleAuthor_split[0].partition(' ')[0]\n",
    "            ArticlesName = ArticleAuthor_split[0].partition(' ')[2]\n",
    "            ArticlesSurnameSecond = ArticleAuthor_split[1].partition(' ')[0]\n",
    "            ArticlesNameSecond = ArticleAuthor_split[1].partition(' ')[2]\n",
    "            with open(\"../INPUT_data/authors_with_id.csv\", 'r') as authors_with_id:   \n",
    "                csv_authors = csv.reader(authors_with_id)\n",
    "                ## AuthorTarget = [row[2] for row in csv_authors if ArticlesSurname in row[0]]  this creates list, while I want item\n",
    "                for row in csv_authors:\n",
    "                    if (ArticlesSurname == row[0] and ArticlesName == row[1]):\n",
    "                        AuthorTarget = row[2]\n",
    "                    if (ArticlesSurnameSecond == row[0] and ArticlesNameSecond == row[1]):\n",
    "                        AuthorTargetSecond = row[2]\n",
    "        else:\n",
    "            ArticlesSurname = ArticleAuthor_split[0]\n",
    "            ArticlesSurnameSecond = ArticleAuthor_split[1].partition(' ')[0]\n",
    "            ArticlesNameSecond = ArticleAuthor_split[1].partition(' ')[2]\n",
    "            with open(\"../INPUT_data/authors_with_id.csv\", 'r') as authors_with_id:   \n",
    "                csv_authors = csv.reader(authors_with_id)\n",
    "                ## AuthorTarget = [row[2] for row in csv_authors if ArticlesSurname in row[0]]  this creates list, while I want item\n",
    "                for row in csv_authors:\n",
    "                    if (ArticlesSurname == row[0]):\n",
    "                        AuthorTarget = row[2]\n",
    "                    if (ArticlesSurnameSecond == row[0] and ArticlesNameSecond == row[1]):\n",
    "                        AuthorTargetSecond = row[2]\n",
    "    else:\n",
    "        if (' ' in ArticleAuthor):\n",
    "            ArticlesSurname = ArticleAuthor.partition(' ')[0]\n",
    "            ArticlesName = ArticleAuthor.partition(' ')[2]\n",
    "            with open(\"../INPUT_data/authors_with_id.csv\", 'r') as authors_with_id:   \n",
    "                csv_authors = csv.reader(authors_with_id)\n",
    "                ## AuthorTarget = [row[2] for row in csv_authors if ArticlesSurname in row[0]]  this creates list, while I want item\n",
    "                for row in csv_authors:\n",
    "                    if (ArticlesSurname == row[0] and ArticlesName == row[1]):\n",
    "                        AuthorTargetSingle = row[2]\n",
    "        else:\n",
    "            ArticlesSurname = ArticleAuthor\n",
    "            with open(\"../INPUT_data/authors_with_id.csv\", 'r') as authors_with_id:   \n",
    "                csv_authors = csv.reader(authors_with_id)\n",
    "                ## AuthorTarget = [row[2] for row in csv_authors if ArticlesSurname in row[0]]  this creates list, while I want item\n",
    "                for row in csv_authors:\n",
    "                    if (ArticlesSurname == row[0]):\n",
    "                        AuthorTargetSingle = row[2]  \n",
    "                        \n",
    "                    \n",
    "    ## -----------------------> label\n",
    "    if (ArticleAuthor != '' and PublicationHasTitle != '' and BookSectionIsPartOf != '' and Date != ''):\n",
    "        BookSectionLabelComplete = \"pub_\"+ArticleAuthor+' ___ '+PublicationHasTitle+' ___ '+BookSectionIsPartOf+' ___ '+Date\n",
    "    else:\n",
    "        if (ArticleAuthor != '' and PublicationHasTitle != '' and PeriodicalTarget != ''):\n",
    "            BookSectionLabelComplete = \"pub_\"+ArticleAuthor+' ___ '+PublicationHasTitle+' ___ '+BookSectionIsPartOf\n",
    "        else:\n",
    "            if (ArticleAuthor != '' and PublicationHasTitle != '' and Date != ''):\n",
    "                BookSectionLabelComplete = \"pub_\"+ArticleAuthor+' ___ '+PublicationHasTitle+' ___ '+Date\n",
    "            else:\n",
    "                if (ArticleAuthor != '' and PeriodicalTarget != '' and Date != ''):\n",
    "                    BookSectionLabelComplete = \"pub_\"+ArticleAuthor+' ___ '+BookSectionIsPartOf+' ___ '+Date\n",
    "                else:\n",
    "                    if (PublicationHasTitle != '' and PeriodicalTarget != '' and Date != ''):\n",
    "                        BookSectionLabelComplete = \"pub_\"+PublicationHasTitle+' ___ '+BookSectionIsPartOf+' ___ '+Date\n",
    "\n",
    "    BookSectionLabel = re.sub(r\"\\(([^\\)]+)\\)\", \"\", BookSectionLabelComplete)\n",
    "\n",
    "    \n",
    "                \n",
    "                \n",
    "    \n",
    "    ###################################\n",
    "    #### REGISTERING NAMESPACES\n",
    "    ###################################\n",
    "    NS_ROUD = \"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" \n",
    "    NS_KNORAIMPORT = \"http://api.knora.org/ontology/knoraXmlImport/v1#\"\n",
    "    ET.register_namespace(\"p0112-roud-oeuvres\", NS_ROUD)\n",
    "    ET.register_namespace(\"knoraXmlImport\", NS_KNORAIMPORT)\n",
    "\n",
    "    \n",
    "    ###################################\n",
    "    ## DEFINE ELEMENTS WITH NS\n",
    "    ###################################\n",
    "    BookSectionNS = ET.QName(NS_ROUD, \"BookSection\")\n",
    "    labelNS = ET.QName(NS_KNORAIMPORT, \"label\")\n",
    "    bookSectionIsInPagesNS = ET.QName(NS_ROUD, \"bookSectionIsInPages\")\n",
    "    bookSectionIsPartOfNS = ET.QName(NS_ROUD, \"bookSectionIsPartOf\")\n",
    "    hasPublicationTypeNS = ET.QName(NS_ROUD, \"hasPublicationType\")\n",
    "    isInBookVolumeNS = ET.QName(NS_ROUD, \"isInBookVolume\")\n",
    "    bookSectionHasPublisherNS = ET.QName(NS_ROUD, \"bookSectionHasPublisher\")\n",
    "    PublisherNS = ET.QName(NS_ROUD, \"Publisher\")\n",
    "    publicationHasAuthorNS = ET.QName(NS_ROUD, \"publicationHasAuthor\")\n",
    "    AuthorNS = ET.QName(NS_ROUD, \"Author\")\n",
    "    publicationHasTitleNS = ET.QName(NS_ROUD, \"publicationHasTitle\")\n",
    "    hasCollaboratorsNS = ET.QName(NS_ROUD, \"hasCollaborators\")\n",
    "    publicationHasDateNS = ET.QName(NS_ROUD, \"publicationHasDate\")\n",
    "    publicationHasInternalCommentNS = ET.QName(NS_ROUD, \"publicationHasInternalComment\")\n",
    "    publicationIsTranscribedNS = ET.QName(NS_ROUD, \"publicationIsTranscribed\")\n",
    "    originalIsInCrlrArchiveNS = ET.QName(NS_ROUD, \"originalIsInCrlrArchive\")\n",
    "    \n",
    "    \n",
    "    ###################################\n",
    "    ## CREATE ELEMENTS AND ATTRIBUTES (AS PREVIOUSLY DEFINED WITH NS) AND ASSIGN THEM CONTENT\n",
    "    ###################################\n",
    "    \n",
    "    BookSection = ET.Element(BookSectionNS, attrib={'id':Publicationid}) \n",
    "    \n",
    "    label = ET.SubElement(BookSection, labelNS)\n",
    "    label.text = BookSectionLabel\n",
    "    \n",
    "    ## -----------------------------> bookSectionHasPublisher\n",
    "    if (publisherName != ''):\n",
    "        bookSectionHasPublisher = ET.SubElement(BookSection, bookSectionHasPublisherNS)\n",
    "        Publisher = ET.SubElement(bookSectionHasPublisher, PublisherNS, attrib={'knoraType':'link_value', 'linkType':'ref', 'target':PublisherTarget})\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> bookSectionIsInPages\n",
    "    if (BookSectionIsInPages!= ''):\n",
    "        bookSectionIsInPages = ET.SubElement(BookSection, bookSectionIsInPagesNS, attrib={'knoraType':'richtext_value'})\n",
    "        bookSectionIsInPages.text = BookSectionIsInPages\n",
    "        \n",
    "    \n",
    "        \n",
    "    ## -----------------------------> BookSectionIsPartOf\n",
    "    if (BookSectionIsPartOf!= ''):\n",
    "        bookSectionIsPartOf = ET.SubElement(BookSection, bookSectionIsPartOfNS, attrib={'knoraType':'richtext_value'})\n",
    "        bookSectionIsPartOf.text = BookSectionIsPartOf\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> hasCollaborators\n",
    "    if (HasCollaborators != ''):\n",
    "        hasCollaborators = ET.SubElement(BookSection, hasCollaboratorsNS, attrib={'knoraType':'richtext_value'})\n",
    "        hasCollaborators.text = HasCollaborators\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> hasPublicationType\n",
    "    hasPublicationType = ET.SubElement(BookSection, hasPublicationTypeNS, attrib={'knoraType':'hlist_value'})\n",
    "    hasPublicationType.text = HasPublicationType  ## use variable defined with name of the publisher corresponding to second row\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> isInBookVolume\n",
    "    if (IsInBookVolume != ''):\n",
    "        isInBookVolume = ET.SubElement(BookSection, isInBookVolumeNS, attrib={'knoraType':'richtext_value'})\n",
    "        isInBookVolume.text = IsInBookVolume\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> OriginalIsInCrlrArchive\n",
    "    if (OriginalIsInCrlrArchive != ''):\n",
    "        originalIsInCrlrArchive = ET.SubElement(BookSection, originalIsInCrlrArchiveNS, attrib={'knoraType':'richtext_value'})\n",
    "        originalIsInCrlrArchive.text = OriginalIsInCrlrArchive\n",
    "        \n",
    "    \n",
    "    ## -----------------------------> publicationHasAuthor\n",
    "    if (',') in ArticleAuthor:\n",
    "        publicationHasAuthor = ET.SubElement(BookSection, publicationHasAuthorNS)\n",
    "        Author = ET.SubElement(publicationHasAuthor, AuthorNS, attrib={'knoraType':'link_value', 'linkType':'ref', 'target':AuthorTarget})\n",
    "        publicationHasAuthor = ET.SubElement(BookSection, publicationHasAuthorNS)\n",
    "        Author = ET.SubElement(publicationHasAuthor, AuthorNS, attrib={'knoraType':'link_value', 'linkType':'ref', 'target':AuthorTargetSecond})\n",
    "    else:\n",
    "        publicationHasAuthor = ET.SubElement(BookSection, publicationHasAuthorNS)\n",
    "        Author = ET.SubElement(publicationHasAuthor, AuthorNS, attrib={'knoraType':'link_value', 'linkType':'ref', 'target':AuthorTargetSingle})\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## -----------------------------> publicationHasDate\n",
    "    if (Date != ''):\n",
    "        publicationHasDate = ET.SubElement(BookSection, publicationHasDateNS, attrib={'knoraType':'date_value'})\n",
    "    \n",
    "    if ('(' in Date):\n",
    "        if len(Date1) > 7:\n",
    "            if len(Date2) > 3:   \n",
    "                publicationHasDate.text = PeriodMD\n",
    "            else:\n",
    "                publicationHasDate.text = PeriodD\n",
    "        else:\n",
    "            publicationHasDate.text = PeriodM\n",
    "    else:\n",
    "        if (pattern.match(Date)):\n",
    "            publicationHasDate.text = PeriodY\n",
    "        else:\n",
    "            if (Date != ''):\n",
    "                publicationHasDate.text = PublicationHasDate\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> publicationHasInternalComment\n",
    "    if (PublicationHasInternalComment != ''):\n",
    "        publicationHasInternalComment = ET.SubElement(BookSection, publicationHasInternalCommentNS, attrib={'knoraType':'richtext_value'})\n",
    "        publicationHasInternalComment.text = PublicationHasInternalComment\n",
    "        \n",
    "    \n",
    "    ## -----------------------------> publicationHasTitle\n",
    "    publicationHasTitle = ET.SubElement(BookSection, publicationHasTitleNS, attrib={'knoraType':'richtext_value'})\n",
    "    publicationHasTitle.text = PublicationHasTitle\n",
    "    \n",
    "    \n",
    "     ## -----------------------------> publicationIsTranscribed\n",
    "    if (PublicationIsTranscribed != ''):\n",
    "        publicationIsTranscribed = ET.SubElement(BookSection, publicationIsTranscribedNS, attrib={'knoraType':'richtext_value'})\n",
    "        publicationIsTranscribed.text = PublicationIsTranscribed\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    tree = ET.tostring(BookSection, encoding=\"unicode\")\n",
    "    o.write('\\n''\\n'+ tree)\n",
    "\n",
    "## WRITE END OF THE XML FILE\n",
    "with o:  ## this is to append the text, if just write o.write does not work here (why??)\n",
    "    o.write('\\n'+'</knoraXmlImport:resources>')\n",
    "\n",
    "o.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### BROWSE AN XML DOCUMENT (TO BE USED BELOW FOR CREATING FICHES AND REFERRING TO THE BIBLIOGRAPHY)\n",
    "###\n",
    "\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "\n",
    "tree_bibliodata = ET.parse('../INPUT_data/bibliography_id_correspondance.xml')\n",
    "root = tree_bibliodata.getroot()\n",
    "for publication in root:\n",
    "    publication_id = publication.get('id')\n",
    "    print(publication_id)\n",
    "    namespaces = {'p0112-roud-oeuvres': 'http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#'} \n",
    "    ### TITLE\n",
    "    publicationHasTitle = publication.findall('./p0112-roud-oeuvres:publicationHasTitle', namespaces)[0].text\n",
    "    #if len(publicationHasTitle.split()) > 10:  ### it title is too long, take only first 10 words\n",
    "         # do something\n",
    "    if (publication.tag == \"{http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#}PeriodicalArticle\" or publication.tag == \"{http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#}BookSection\"):\n",
    "        title = \"« \"+publicationHasTitle+\" »\"\n",
    "    else:\n",
    "        title = \"<i>\"+publicationHasTitle+\"</i>\"\n",
    "    ### AUTHOR    \n",
    "    publicationHasAuthor = publication.find('./p0112-roud-oeuvres:publicationHasAuthor', namespaces)\n",
    "    ### DATE\n",
    "    publicationHasDate = publication.find('./p0112-roud-oeuvres:publicationHasDate', namespaces)\n",
    "    ### BIBLIO = AUTHOR + TITLE + DATE\n",
    "    if (publicationHasAuthor is None):\n",
    "        if (publicationHasDate is None):\n",
    "            biblio = title\n",
    "        else:\n",
    "            date = publication.findall('./p0112-roud-oeuvres:publicationHasDate', namespaces)[0].text.split(\"GREGORIAN:\")[1].split(\"-\")[0].split(\" CE\")[0]\n",
    "            biblio = title+\", \"+date\n",
    "    else:\n",
    "        author = publication.findall('./p0112-roud-oeuvres:publicationHasAuthor', namespaces)[0].findall('./p0112-roud-oeuvres:Author', namespaces)[0].get('target').split(\"_\")[0]\n",
    "        if (publicationHasDate is None):\n",
    "            biblio = author+\", \"+title\n",
    "        else:\n",
    "            date = publication.findall('./p0112-roud-oeuvres:publicationHasDate', namespaces)[0].text.split(\"GREGORIAN:\")[1].split(\"-\")[0].split(\" CE\")[0]\n",
    "            biblio = author+\", \"+title+\", \"+date\n",
    "    print(biblio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = '<p>Version interm&eacute;diaire entre [Biblio 207] et [Biblio 282].</p><p>Dat&eacute; &agrave; la main: Novembre 35-novembre 41. novembre 49.</p><p>Repris dans [Biblio 517].</p>'\n",
    "findBiblioNumber = re.compile(r'\\[Biblio (\\d+)\\]')\n",
    "for biblioOccur in re.finditer(findBiblioNumber, test):\n",
    "    biblioNumber = biblioOccur.group(1)\n",
    "    print(biblioNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### CREATE XML FROM CSV (FICHES)\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "from xml.etree import ElementTree as ET\n",
    "import csv, re\n",
    "from datetime import datetime\n",
    "\n",
    "f = open('../INPUT_data/fiches.csv')   ## should not be manipulated, because when changing the content of certain cells go to the next cell and the entire row is erroneous\n",
    "o = open('../OUTPUT_xml/fiches.xml', 'w')\n",
    "\n",
    "csv_f = csv.reader(f, delimiter='$', quotechar=\"§\")   \n",
    "data = []\n",
    "\n",
    "for row in csv_f: \n",
    "   data.append(row)\n",
    "f.close()\n",
    "\n",
    "#print(data[10:11])\n",
    "\n",
    "\n",
    "## [0] id, [1] titre, [2] archive_id, [3] oldcote, [4] cote, [5] ensemble_id, [6] type_id, [7] annotation, [8] support_id, \n",
    "## [9] support_info, [10] instrument_id, [11] color_id, [12] other_tool, [13] statut_id, [14] dates, [15] datation, \n",
    "## [16] datationlist_id, [17] datationcomment, [18] publie, [19] biblio_id, [20] auteurtraduit_id, [21]alreadydigitized, \n",
    "## [22] numerise_info, [23] commentaire, [24] photocopy, [25] resp_id\n",
    "\n",
    "\n",
    "###################################\n",
    "## WRITE DECLARATIONS AND BEGINNING OF THE XML FILE -adding more line breaks for readibility '+'\\n'+' ???-\n",
    "###################################\n",
    "o.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>'+'\\n'+'<knoraXmlImport:resources xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/knoraXmlImport/v1# ../p0112-roud-oeuvres-xml-schemas/p0112-roud-oeuvres.xsd\" xmlns=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\" xmlns:p0112-roud-oeuvres=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\">'+'\\n')\n",
    "\n",
    "\n",
    "    \n",
    "###################################\n",
    "#### REGISTERING NAMESPACES\n",
    "###################################\n",
    "NS_ROUD = \"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" \n",
    "NS_KNORAIMPORT = \"http://api.knora.org/ontology/knoraXmlImport/v1#\"\n",
    "ET.register_namespace(\"p0112-roud-oeuvres\", NS_ROUD)\n",
    "ET.register_namespace(\"knoraXmlImport\", NS_KNORAIMPORT)\n",
    "\n",
    "\n",
    "###################################\n",
    "## DEFINE ELEMENTS WITH NS\n",
    "###################################\n",
    "ManuscriptNS = ET.QName(NS_ROUD, \"Manuscript\")\n",
    "labelNS = ET.QName(NS_KNORAIMPORT, \"label\")\n",
    "hasAnnotationNS = ET.QName(NS_ROUD, \"hasAnnotation\")\n",
    "hasDocumentTypeNS = ET.QName(NS_ROUD, \"hasDocumentType\")\n",
    "hasGeneticStageNS = ET.QName(NS_ROUD, \"hasGeneticStage\")\n",
    "hasOtherWritingToolNS = ET.QName(NS_ROUD, \"hasOtherWritingTool\")\n",
    "hasPublicCommentNS = ET.QName(NS_ROUD, \"hasPublicComment\")\n",
    "hasSupportInfoNS = ET.QName(NS_ROUD, \"hasSupportInfo\")\n",
    "hasSupportTypeNS = ET.QName(NS_ROUD, \"hasSupportType\")\n",
    "hasTranslatedAuthorNS = ET.QName(NS_ROUD, \"hasTranslatedAuthor\")\n",
    "AuthorNS = ET.QName(NS_ROUD, \"Author\")\n",
    "hasWritingColorNS = ET.QName(NS_ROUD, \"hasWritingColor\")\n",
    "hasWritingToolNS = ET.QName(NS_ROUD, \"hasWritingTool\")\n",
    "isPhotocopyNS = ET.QName(NS_ROUD, \"isPhotocopy\")\n",
    "manuscriptHasDateReadableNS = ET.QName(NS_ROUD, \"manuscriptHasDateReadable\")\n",
    "manuscriptHasDateComputableNS = ET.QName(NS_ROUD, \"manuscriptHasDateComputable\")\n",
    "manuscriptHasDateEstablishedComputableNS = ET.QName(NS_ROUD, \"manuscriptHasDateEstablishedComputable\")\n",
    "manuscriptHasDateEstablishedListNS = ET.QName(NS_ROUD, \"manuscriptHasDateEstablishedList\")\n",
    "manuscriptHasDateEstablishedReadableNS = ET.QName(NS_ROUD, \"manuscriptHasDateEstablishedReadable\")\n",
    "manuscriptHasEditorialSetNS = ET.QName(NS_ROUD, \"manuscriptHasEditorialSet\")\n",
    "manuscriptHasInternalCommentNS = ET.QName(NS_ROUD, \"manuscriptHasInternalComment\")\n",
    "manuscriptHasOldShelfmarkNS = ET.QName(NS_ROUD, \"manuscriptHasOldShelfmark\")\n",
    "manuscriptHasPublishedReferenceNS = ET.QName(NS_ROUD, \"manuscriptHasPublishedReference\")\n",
    "PublicationNS = ET.QName(NS_ROUD, \"Publication\")\n",
    "manuscriptHasShelfmarkNS = ET.QName(NS_ROUD, \"manuscriptHasShelfmark\")\n",
    "manuscriptHasTitleNS = ET.QName(NS_ROUD, \"manuscriptHasTitle\")\n",
    "manuscriptIsDigitizedNS = ET.QName(NS_ROUD, \"manuscriptIsDigitized\")\n",
    "manuscriptIsInArchiveNS = ET.QName(NS_ROUD, \"manuscriptIsInArchive\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###################################\n",
    "## PREPARE CONTENT OF ELEMENTS AND ATTRIBUTES\n",
    "###################################\n",
    "\n",
    "\n",
    "## to avoid undefined entities when parsing the XML present is certain cells of the CSV\n",
    "## \"https://dev.w3.org/html5/html-author/charref\"\n",
    "entities_declaration = '''  <!DOCTYPE HTML PUBLIC \"-//W3C//ENTITIES //EN//HTML\" \n",
    "                            \"https://www.w3.org/TR/html4/sgml/entities.html\"\n",
    "                            [   <!ENTITY agrave 'à'>\n",
    "                                <!ENTITY egrave 'è'>\n",
    "                                <!ENTITY igrave 'ì'>\n",
    "                                <!ENTITY ograve 'ò'>\n",
    "                                <!ENTITY ugrave 'ù'>\n",
    "                                <!ENTITY Agrave 'À'>\n",
    "                                <!ENTITY Egrave 'È'>\n",
    "                                <!ENTITY Igrave 'Ì'>\n",
    "                                <!ENTITY Ograve 'Ò'>\n",
    "                                <!ENTITY Ugrave 'Ù'>\n",
    "                                <!ENTITY eacute 'é'>\n",
    "                                <!ENTITY Eacute 'É'>\n",
    "                                <!ENTITY acirc 'â'>\n",
    "                                <!ENTITY ecirc 'ê'>\n",
    "                                <!ENTITY icirc 'î'>\n",
    "                                <!ENTITY ocirc 'ô'>\n",
    "                                <!ENTITY ucirc 'û'>\n",
    "                                <!ENTITY Acirc 'Â'>\n",
    "                                <!ENTITY Ecirc 'Ê'>\n",
    "                                <!ENTITY Icirc 'Î'>\n",
    "                                <!ENTITY Ocirc 'Ô'>\n",
    "                                <!ENTITY Ucirc 'Û'>\n",
    "                                <!ENTITY auml 'ä'>\n",
    "                                <!ENTITY euml 'ë'>\n",
    "                                <!ENTITY iuml 'ï'>\n",
    "                                <!ENTITY ouml 'ö'>\n",
    "                                <!ENTITY uuml 'ü'>\n",
    "                                <!ENTITY yuml 'ÿ'>\n",
    "                                <!ENTITY Auml 'Ä'>\n",
    "                                <!ENTITY Euml 'Ë'>\n",
    "                                <!ENTITY Iuml 'Ï'>\n",
    "                                <!ENTITY Ouml 'Ö'>\n",
    "                                <!ENTITY Uuml 'Ü'>\n",
    "                                <!ENTITY ccedil 'ç'>\n",
    "                                <!ENTITY Ccedil 'Ç'>\n",
    "                                <!ENTITY oelig 'œ'>\n",
    "                                <!ENTITY OElig 'Œ'>\n",
    "                                <!ENTITY szlig '&#223;'>\n",
    "                                \n",
    "                                <!ENTITY rsquo \"'\">  <!-- as if it was &apos; --> \n",
    "                                <!ENTITY lsquo \"'\">  <!-- as if it was &apos; -->\n",
    "                                \n",
    "                                <!ENTITY laquo '«'>\n",
    "                                <!ENTITY raquo '»'>\n",
    "                                <!ENTITY hellip '…'>\n",
    "                                <!ENTITY nbsp ' '>\n",
    "                                <!ENTITY ndash '&#8211;'>\n",
    "                                <!ENTITY deg '&#176;'>\n",
    "                                \n",
    "                                <!ENTITY Alpha '&#913;'>\n",
    "                                <!ENTITY Delta '&#916;'>\n",
    "                                <!ENTITY Tau '&#932;'>\n",
    "                                <!ENTITY Epsilon '&#917;'>\n",
    "                                <!ENTITY alpha '&#945;'>\n",
    "                                <!ENTITY beta '&#946;'>\n",
    "                                <!ENTITY pi '&#928;'>\n",
    "                                <!ENTITY omicron '&#959;'>\n",
    "                                <!ENTITY lambda '&#955;'>\n",
    "                                <!ENTITY nu '&#957;'>\n",
    "                                <!ENTITY gamma '&#947;'>\n",
    "                                <!ENTITY upsilon '&#965;'>\n",
    "                                <!ENTITY iota '&#953;'>\n",
    "                                <!ENTITY tau '&#964;'>\n",
    "                                <!ENTITY omega '&#969;'>\n",
    "                                <!ENTITY epsilon '&#949;'>\n",
    "                                <!ENTITY mu '&#956;'>\n",
    "                                <!ENTITY sigmaf '&#962;'>\n",
    "                                <!ENTITY eta '&#951;'>\n",
    "                                <!ENTITY chi '&#967;'>\n",
    "                                <!ENTITY rho '&#961;'>\n",
    "                                <!ENTITY kappa '&#954;'> ]>  '''\n",
    "\n",
    "\n",
    "for row in data[0:]:\n",
    "    \n",
    "    \n",
    "    ## -----------------------> @id \n",
    "    ficheid = 'fiche'+row[0] \n",
    "    \n",
    "    \n",
    "    ## -----------------------> hasAnnotation\n",
    "    if (row[7] == 'oui'):\n",
    "        hasAnnotation_content = 'true'\n",
    "    else:\n",
    "        hasAnnotation_content = 'false'    \n",
    "    \n",
    "    \n",
    "    ## -----------------------> hasDocumentType\n",
    "    documentType = row[6]\n",
    "    if (documentType == '1'):\n",
    "        hasDocumentType_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasDocumentType-manuscript'\n",
    "    if (documentType == '2'):\n",
    "        hasDocumentType_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasDocumentType-dactylo'\n",
    "    if (documentType == '3'):\n",
    "        hasDocumentType_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasDocumentType-imprime'\n",
    "    \n",
    "    \n",
    "    ## -----------------------> hasGeneticStage\n",
    "    geneticStage = row[13]\n",
    "    if (geneticStage == '1'):\n",
    "        hasGeneticStage_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasGeneticStage-note'\n",
    "    if (geneticStage == '2'):\n",
    "        hasGeneticStage_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasGeneticStage-plan'\n",
    "    if (geneticStage == '3'):\n",
    "        hasGeneticStage_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasGeneticStage-brouillon'\n",
    "    if (geneticStage == '4'):\n",
    "        hasGeneticStage_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasGeneticStage-miseAuNet'\n",
    "    if (geneticStage == '5'):\n",
    "        hasGeneticStage_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasGeneticStage-manuscritDefinitif'\n",
    "    if (geneticStage == '6'):\n",
    "        hasGeneticStage_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasGeneticStage-epreuvesCorriges'\n",
    "    if (geneticStage == '7'):\n",
    "        hasGeneticStage_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasGeneticStage-originalCorrige'\n",
    "    if (geneticStage == '8'):\n",
    "        hasGeneticStage_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasGeneticStage-verifier'\n",
    "    if (geneticStage == '10'):\n",
    "        hasGeneticStage_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasGeneticStage-liste'\n",
    "    if (geneticStage == '12'):\n",
    "        hasGeneticStage_content = ''\n",
    "     \n",
    "    \n",
    "    ## -----------------------> hasOtherWritingTool\n",
    "    otherWritingTool = row[12]\n",
    "    if (otherWritingTool != ''):\n",
    "        ## attach <text> to the xml in the cell, so it has a wrapping element and the function 'fromstring' works\n",
    "        hasOtherWritingTool_content = '<text xmlns=\"\">'+otherWritingTool+'</text>'\n",
    "        \n",
    "        \n",
    "    ## -----------------------> hasPublicComment\n",
    "    publicComment = row[23]\n",
    "    if (publicComment != ''):\n",
    "        if (\"[Biblio\" in publicComment):\n",
    "            # add link\n",
    "            refbiblio = re.compile(r'\\[(Biblio (\\d+))\\]')\n",
    "            publicComment_link = re.sub(refbiblio, r'<a class=\"salsah-link\" href=\"'+\"ref:\"+r'\\1\">[\\1]</a>', publicComment)\n",
    "            publicComment_linkref = re.sub('ref:Biblio ','ref:biblio_',publicComment_link)\n",
    "            \n",
    "            # isolate biblio_id in the comment \n",
    "            for biblio_number in re.finditer(refbiblio,publicComment_linkref):\n",
    "                biblio_number = biblio_number.group(2)\n",
    "                biblio_id = 'biblio_'+biblio_number\n",
    "                \n",
    "                # find corresponding biblio_id in bibliography xml file and build correspoding bibliographic reference\n",
    "                tree_bibliodata = ET.parse('../INPUT_data/bibliography_id_correspondance.xml')\n",
    "                root = tree_bibliodata.getroot()\n",
    "                for publication in root:\n",
    "                    publication_id = publication.attrib['id']\n",
    "                    if (biblio_id == publication_id):\n",
    "                        namespaces = {'p0112-roud-oeuvres': 'http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#'} \n",
    "                        # TITLE\n",
    "                        ref_publicationHasTitle = publication.findall('./p0112-roud-oeuvres:publicationHasTitle', namespaces)[0].text\n",
    "                        #if len(publicationHasTitle.split()) > 10:  ### it title is too long, take only first 10 words\n",
    "                             # do something\n",
    "                        if (publication.tag == \"{http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#}PeriodicalArticle\" or publication.tag == \"{http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#}BookSection\"):\n",
    "                            ref_title = \"« \"+ref_publicationHasTitle+\" »\"\n",
    "                        else:\n",
    "                            ref_title = \"<i>\"+ref_publicationHasTitle+\"</i>\"\n",
    "                        # AUTHOR    \n",
    "                        ref_publicationHasAuthor = publication.find('./p0112-roud-oeuvres:publicationHasAuthor', namespaces)\n",
    "                        # DATE\n",
    "                        ref_publicationHasDate = publication.find('./p0112-roud-oeuvres:publicationHasDate', namespaces)\n",
    "                        # BIBLIO = AUTHOR + TITLE + DATE\n",
    "                        if (ref_publicationHasAuthor is None):\n",
    "                            if (ref_publicationHasDate is None):\n",
    "                                ref_biblioInPublicComment = ref_title\n",
    "                            else:\n",
    "                                ref_date = publication.findall('./p0112-roud-oeuvres:publicationHasDate', namespaces)[0].text.split(\"GREGORIAN:\")[1].split(\"-\")[0].split(\" CE\")[0]\n",
    "                                biblioInPublicComment = ref_title+\", \"+ref_date\n",
    "                        else:\n",
    "                            ref_author = publication.findall('./p0112-roud-oeuvres:publicationHasAuthor', namespaces)[0].findall('./p0112-roud-oeuvres:Author', namespaces)[0].get('target').split(\"_\")[0]\n",
    "                            if (ref_publicationHasDate is None):\n",
    "                                biblioInPublicComment = ref_author+\", \"+ref_title\n",
    "                            else:\n",
    "                                ref_date = publication.findall('./p0112-roud-oeuvres:publicationHasDate', namespaces)[0].text.split(\"GREGORIAN:\")[1].split(\"-\")[0].split(\" CE\")[0]\n",
    "                                biblioInPublicComment = ref_author+\", \"+ref_title+\", \"+ref_date\n",
    "                # replace [Biblio number] with bibliographic reference\n",
    "                biblioToBeReplaced = '\\[Biblio '+biblio_number+'\\]'\n",
    "                publicComment_linkref = re.sub(biblioToBeReplaced,biblioInPublicComment,publicComment_linkref)\n",
    "            \n",
    "            hasPublicComment_content = '<text xmlns=\"\">'+publicComment_linkref+'</text>'\n",
    "        else:\n",
    "            hasPublicComment_content = '<text xmlns=\"\">'+publicComment+'</text>'\n",
    "        \n",
    "    ## -----------------------> hasSupportInfo\n",
    "    supportInfo = row[9]\n",
    "    if (supportInfo != ''):\n",
    "        hasSupportInfo_content = '<text xmlns=\"\">'+supportInfo+'</text>'\n",
    "        \n",
    "    ## -----------------------> hasSupportType\n",
    "    supportType = row[8]\n",
    "    if (supportType == '1'):\n",
    "        hasSupportType_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasSupportType-feuillet'\n",
    "    if (supportType == '2'):\n",
    "        hasSupportType_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasSupportType-agenda'\n",
    "    if (supportType == '3'):\n",
    "        hasSupportType_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasSupportType-carnet'\n",
    "    if (supportType == '4'):\n",
    "        hasSupportType_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasSupportType-cahier'\n",
    "    if (supportType == '5'):\n",
    "        hasSupportType_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasSupportType-enveloppe'\n",
    "    if (supportType == '6'):\n",
    "        hasSupportType_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasSupportType-divers'\n",
    "    if (supportType == '7'):\n",
    "        hasSupportType_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasSupportType-imprimesReliesParRoud'\n",
    "    if (supportType == '8'):\n",
    "        hasSupportType_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasSupportType-blocNotes'\n",
    "    if (supportType == '9'):\n",
    "        hasSupportType_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasSupportType-imprime'\n",
    "        \n",
    "    \n",
    "    ## -----------------------> hasTranslatedAuthor\n",
    "    translatedAuthor = row[20]\n",
    "    if (translatedAuthor == '1'):\n",
    "        hasTranslatedAuthor_content = ''\n",
    "    if (translatedAuthor == '2'):\n",
    "        hasTranslatedAuthor_content = 'Hölderlin_Friedrich'\n",
    "    if (translatedAuthor == '3'):\n",
    "        hasTranslatedAuthor_content = 'Rilke_Rainer_Maria'\n",
    "    if (translatedAuthor == '4'):\n",
    "        hasTranslatedAuthor_content = 'Novalis'\n",
    "    if (translatedAuthor == '5'):\n",
    "        hasTranslatedAuthor_content = 'Trakl_Georg'\n",
    "    if (translatedAuthor == '6'):\n",
    "        hasTranslatedAuthor_content = 'Gudmundsson_Kristmann'\n",
    "    if (translatedAuthor == '7'):\n",
    "        hasTranslatedAuthor_content = 'Brentano_Clemens'\n",
    "    if (translatedAuthor == '8'):\n",
    "        hasTranslatedAuthor_content = 'Heym_Georg'\n",
    "    if (translatedAuthor == '9'):\n",
    "        hasTranslatedAuthor_content = 'Goethe_Johann_Wolfgang_von'\n",
    "    if (translatedAuthor == '10'):\n",
    "        hasTranslatedAuthor_content = 'Eichendorff_Joseph_von'\n",
    "    if (translatedAuthor == '11'):\n",
    "        hasTranslatedAuthor_content = 'Platen_August_von'\n",
    "    if (translatedAuthor == '12'):\n",
    "        hasTranslatedAuthor_content = 'Heine_Heinrich'\n",
    "    if (translatedAuthor == '13'):\n",
    "        hasTranslatedAuthor_content = 'Nietzsche_Friedrich'\n",
    "    if (translatedAuthor == '14'):\n",
    "        hasTranslatedAuthor_content = 'Hesse_Hermann'\n",
    "    if (translatedAuthor == '15'):\n",
    "        hasTranslatedAuthor_content = 'Werfel_Franz'\n",
    "    if (translatedAuthor == '16'):\n",
    "        hasTranslatedAuthor_content = 'Bergengruen_Werner'\n",
    "    if (translatedAuthor == '17'):\n",
    "        hasTranslatedAuthor_content = 'Dürer_Albrecht'\n",
    "    if (translatedAuthor == '18'):\n",
    "        hasTranslatedAuthor_content = 'Müller_Wilhelm'\n",
    "    if (translatedAuthor == '19'):\n",
    "        hasTranslatedAuthor_content = 'Lavater-Sloman_Mary'\n",
    "    if (translatedAuthor == '20'):\n",
    "        hasTranslatedAuthor_content = 'Leisinger_Hermann'\n",
    "    if (translatedAuthor == '21'):\n",
    "        hasTranslatedAuthor_content = 'DAnnunzio_Gabriele'\n",
    "    if (translatedAuthor == '22'):\n",
    "        hasTranslatedAuthor_content = 'Montale_Eugenio'\n",
    "    if (translatedAuthor == '23'):\n",
    "        hasTranslatedAuthor_content = 'Barilli_Bruno'\n",
    "    if (translatedAuthor == '24'):\n",
    "        hasTranslatedAuthor_content = 'Cardarelli_Vincenzo'\n",
    "    if (translatedAuthor == '25'):\n",
    "        hasTranslatedAuthor_content = 'Buonarroti_Michelangelo'\n",
    "    if (translatedAuthor == '26'):\n",
    "        hasTranslatedAuthor_content = 'Coccioli_Carlo'\n",
    "    if (translatedAuthor == '28'):\n",
    "        hasTranslatedAuthor_content = 'Lejeune_Robert'\n",
    "    if (translatedAuthor == '29'):\n",
    "        hasTranslatedAuthor_content = 'Gotthelf_Jeremias'\n",
    "    if (translatedAuthor == '30'):\n",
    "        hasTranslatedAuthor_content = 'Kleist_Heinrich_von'\n",
    "    if (translatedAuthor == '31'):\n",
    "        hasTranslatedAuthor_content = 'Oeschger_Johannes'\n",
    "        \n",
    "        \n",
    "    \n",
    "    ## -----------------------> hasWritingColor\n",
    "    writingColor = row[11]\n",
    "    if (writingColor == '1'):\n",
    "        hasWritingColor_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasWritingColor-black'\n",
    "    if (writingColor == '2'):\n",
    "        hasWritingColor_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasWritingColor-red'\n",
    "    if (writingColor == '3'):\n",
    "        hasWritingColor_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasWritingColor-blue'\n",
    "    if (writingColor == '4'):\n",
    "        hasWritingColor_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasWritingColor-rose'\n",
    "    if (writingColor == '5'):\n",
    "        hasWritingColor_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasWritingColor-violet'\n",
    "    if (writingColor == '6'):\n",
    "        hasWritingColor_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasWritingColor-gray'\n",
    "    if (writingColor == '7'):\n",
    "        hasWritingColor_content = ''\n",
    "    \n",
    "    \n",
    "    ## -----------------------> hasWritingTool\n",
    "    writingTool = row[10]\n",
    "    if (writingTool == '1'):\n",
    "        hasWritingTool_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasWritingTool-pencil'\n",
    "    if (writingTool == '2'):\n",
    "        hasWritingTool_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasWritingTool-typingMachine'\n",
    "    if (writingTool == '3'):\n",
    "        hasWritingTool_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasWritingTool-quill'\n",
    "    if (writingTool == '4'):\n",
    "        hasWritingTool_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasWritingTool-ballpointPen'\n",
    "    if (writingTool == '5'):\n",
    "        hasWritingTool_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasWritingTool-feltTip'\n",
    "    if (writingTool == '6'):\n",
    "        hasWritingTool_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasWritingTool-other'\n",
    "    if (writingTool == '7'):\n",
    "        hasWritingTool_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasWritingTool-toBeDetermined'\n",
    "    if (writingTool == '8'):\n",
    "        hasWritingTool_content = ''\n",
    "    \n",
    "    \n",
    "    ## -----------------------> isPhotocopy\n",
    "    if (row[24] == 'oui'):\n",
    "        isPhotocopy_content = 'true'\n",
    "    else:\n",
    "        isPhotocopy_content = 'false'    \n",
    "        \n",
    "        \n",
    "    ## -----------------------> manuscriptHasDateComputable   \n",
    "    date = row[14]\n",
    "    if (date != '' and not date.startswith('0000#')): \n",
    "        if ('–' in date):   # it is a period\n",
    "            date12_split = re.split(' – ', date)  ## split in date1 and date2\n",
    "            date1 = date12_split[0]\n",
    "            date2 = date12_split[1]\n",
    "            manuscriptHasDateComputable_content = 'GREGORIAN:'+date1+' CE:'+date2+' CE'\n",
    "        else:   # no period\n",
    "            manuscriptHasDateComputable_content = 'GREGORIAN:'+date+' CE'\n",
    "\n",
    "            \n",
    "    ## -----------------------> manuscriptHasDateReadable\n",
    "    if (date != '' and not date.startswith('0000#')): \n",
    "        if ('–' in date):   # it is a period\n",
    "            date1_len = len(date1)\n",
    "            if (date1_len > 7):\n",
    "                date1_object = datetime.strptime(date1, '%Y-%m-%d')\n",
    "                date1_string = date1_object.strftime('<%A, >%-d %B %Y')\n",
    "            if (date1_len > 5 and date1_len < 8):\n",
    "                date1_object = datetime.strptime(date1, '%Y-%m')\n",
    "                date1_string = date1_object.strftime('%B %Y')\n",
    "            if (date1_len < 5):\n",
    "                date1_object = datetime.strptime(date1, '%Y')\n",
    "                date1_string = date1_object.strftime('%Y')\n",
    "            date2_len = len(date2)\n",
    "            if (date2_len > 7):\n",
    "                date2_object = datetime.strptime(date2, '%Y-%m-%d')\n",
    "                date2_string = date2_object.strftime('<%A, >%-d %B %Y')\n",
    "            if (date2_len > 5 and date2_len < 8):\n",
    "                date2_object = datetime.strptime(date2, '%Y-%m')\n",
    "                date2_string = date2_object.strftime('%B %Y')\n",
    "            if (date2_len < 5):\n",
    "                date2_object = datetime.strptime(date2, '%Y')\n",
    "                date2_string = date2_object.strftime('%Y')\n",
    "            date_string = date1_string +' - '+date2_string\n",
    "        else:\n",
    "            date_len = len(date)\n",
    "            if (date_len > 7):\n",
    "                date_object = datetime.strptime(date, '%Y-%m-%d')\n",
    "                date_string = date_object.strftime('<%A, >%-d %B %Y')\n",
    "            if (date_len > 5 and date_len < 8):\n",
    "                date_object = datetime.strptime(date, '%Y-%m')\n",
    "                date_string = date_object.strftime('%B %Y')\n",
    "            if (date_len < 5):\n",
    "                date_object = datetime.strptime(date, '%Y')\n",
    "                date_string = date_object.strftime('%Y')\n",
    "        def multipleReplace(text, wordDict):\n",
    "            for key in wordDict:\n",
    "                text = text.replace(key, wordDict[key])\n",
    "            return text\n",
    "        en_fr_months_days = {'January':'janvier', 'February':'février', 'March':'mars', 'April':'avril', 'May':'mai', \n",
    "                             'June':'juin', 'July':'juillet', 'August':'août', 'September':'septembre', \n",
    "                             'October':'octobre', 'November':'novembre', 'December':'décembre', \n",
    "                             'Monday':'lundi', 'Tuesday':'mardi', 'Wednesday':'mercredi', 'Thursday':'jeudi', \n",
    "                             'Friday':'vendredi', 'Saturday':'samedi', 'Sunday':'dimanche', '<':'&#12296;', '>':'&#12297;'}\n",
    "        date_string_fr = multipleReplace(date_string, en_fr_months_days)\n",
    "        manuscriptHasDateReadable_content = '<text xmlns=\"\">'+date_string_fr+'</text>'\n",
    "        # do not delete text, because it is build to work like this\n",
    "    if (date.startswith('0000#')):   #### certain dates have been marked like this to indicate that they do not have the year therefore cannot be transformed into computable dates\n",
    "        uncomplete_date = date.split('0000#',1)[1]\n",
    "        manuscriptHasDateReadable_content = '<text xmlns=\"\">'+uncomplete_date+'</text>'   \n",
    "        \n",
    "    ## -----------------------> manuscriptHasDateEstablishedComputable   \n",
    "    datation = row[15]\n",
    "    if (datation != ''): \n",
    "        if ('–' in datation):   # it is a period\n",
    "            datation12_split = re.split(' – ', datation) \n",
    "            datation1 = datation12_split[0]\n",
    "            datation2 = datation12_split[1]\n",
    "            manuscriptHasDateEstablishedComputable_content = 'GREGORIAN:'+datation1+' CE:'+datation2+' CE'\n",
    "        else:   # no period\n",
    "            manuscriptHasDateEstablishedComputable_content = 'GREGORIAN:'+datation+' CE'\n",
    "    \n",
    "    \n",
    "    ## -----------------------> manuscriptHasDateEstablishedList\n",
    "    dateEstablishedList = row[16]\n",
    "    if (dateEstablishedList != '1'):\n",
    "        if (dateEstablishedList == '2'):\n",
    "            manuscriptHasDateEstablishedList_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-dateEstablishedList-circa'\n",
    "        if (dateEstablishedList == '3'):\n",
    "            manuscriptHasDateEstablishedList_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-dateEstablishedList-before'\n",
    "        if (dateEstablishedList == '4'):\n",
    "            manuscriptHasDateEstablishedList_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-dateEstablishedList-after'\n",
    "  \n",
    "            \n",
    "    ## -----------------------> manuscriptHasDateEstablishedReadable  \n",
    "    datation = row[15]\n",
    "    datation_list = row[16]\n",
    "    datation_comment = row[17]  \n",
    "    #### include biblio in datation comment\n",
    "    if (\"[Biblio\" in datation_comment):\n",
    "        refbiblioin = re.compile(r'\\[(Biblio (\\d+))\\]')\n",
    "        datation_comment_link = re.sub(refbiblioin, r'<a class=\"salsah-link\" href=\"'+\"ref:\"+r'\\1\">[\\1]</a>', datation_comment)\n",
    "        datation_comment_linkref = re.sub('ref:Biblio ','ref:biblio_',datation_comment_link)\n",
    "        datation_comment = datation_comment_linkref\n",
    "    #### make datation readable (copy code above)\n",
    "    if (datation != ''): \n",
    "        if ('–' in datation):   # it is a period\n",
    "            datation1_len = len(datation1)\n",
    "            if (datation1_len > 7):\n",
    "                datation1_object = datetime.strptime(datation1, '%Y-%m-%d')\n",
    "                datation1_string = datation1_object.strftime('<%A, >%-d %B %Y')\n",
    "            if (datation1_len > 5 and datation1_len < 8):\n",
    "                datation1_object = datetime.strptime(datation1, '%Y-%m')\n",
    "                datation1_string = datation1_object.strftime('%B %Y')\n",
    "            if (datation1_len < 5):\n",
    "                datation1_object = datetime.strptime(datation1, '%Y')\n",
    "                datation1_string = datation1_object.strftime('%Y')\n",
    "            datation2_len = len(datation2)\n",
    "            if (datation2_len > 7):\n",
    "                datation2_object = datetime.strptime(datation2, '%Y-%m-%d')\n",
    "                datation2_string = datation2_object.strftime('<%A, >%-d %B %Y')\n",
    "            if (datation2_len > 5 and datation2_len < 8):\n",
    "                datation2_object = datetime.strptime(datation2, '%Y-%m')\n",
    "                datation2_string = datation2_object.strftime('%B %Y')\n",
    "            if (datation2_len < 5):\n",
    "                datation2_object = datetime.strptime(datation2, '%Y')\n",
    "                datation2_string = datation2_object.strftime('%Y')\n",
    "            datation_string = datation1_string +' - '+datation2_string\n",
    "        else:\n",
    "            datation_len = len(datation)\n",
    "            if (datation_len > 7):\n",
    "                datation_object = datetime.strptime(datation, '%Y-%m-%d')\n",
    "                datation_string = datation_object.strftime('<%A, >%-d %B %Y')\n",
    "            if (datation_len > 5 and datation_len < 8):\n",
    "                datation_object = datetime.strptime(datation, '%Y-%m')\n",
    "                datation_string = datation_object.strftime('%B %Y')\n",
    "            if (datation_len < 5):\n",
    "                datation_object = datetime.strptime(datation, '%Y')\n",
    "                datation_string = datation_object.strftime('%Y')\n",
    "        def multipleReplace(text, wordDict):\n",
    "            for key in wordDict:\n",
    "                text = text.replace(key, wordDict[key])\n",
    "            return text\n",
    "        en_fr_months_days = {'January':'janvier', 'February':'février', 'March':'mars', 'April':'avril', 'May':'mai', \n",
    "                             'June':'juin', 'July':'juillet', 'August':'août', 'September':'septembre', \n",
    "                             'October':'octobre', 'November':'novembre', 'December':'décembre', \n",
    "                             'Monday':'lundi', 'Tuesday':'mardi', 'Wednesday':'mercredi', 'Thursday':'jeudi', \n",
    "                             'Friday':'vendredi', 'Saturday':'samedi', 'Sunday':'dimanche', '<':'&#12296;', '>':'&#12297;'}\n",
    "        datation_string_fr = multipleReplace(datation_string, en_fr_months_days)  ### datation in readable format\n",
    "    if (datation != '' and datation_comment != ''):    \n",
    "        manuscriptHasDateEstablishedReadable_content = '<text xmlns=\"\">'+datation_string_fr+'. '+datation_comment+'</text>'\n",
    "    if (datation != '' and datation_comment == ''): \n",
    "        manuscriptHasDateEstablishedReadable_content = '<text xmlns=\"\">'+datation_string_fr+'</text>'\n",
    "    if (datation == '' and datation_comment != ''): \n",
    "        manuscriptHasDateEstablishedReadable_content = '<text xmlns=\"\">'+datation_comment+'</text>'\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## -----------------------> manuscriptHasEditorialSet\n",
    "    editorialSet = row[5]\n",
    "    if (editorialSet == '1'):\n",
    "        manuscriptHasEditorialSet_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasEditorialSet-oeuvrePoetique'\n",
    "    if (editorialSet == '2'):\n",
    "        manuscriptHasEditorialSet_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasEditorialSet-journal'\n",
    "    if (editorialSet == '3'):\n",
    "        manuscriptHasEditorialSet_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasEditorialSet-propos'\n",
    "    if (editorialSet == '4'):\n",
    "        manuscriptHasEditorialSet_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasEditorialSet-traduction'\n",
    "    if (editorialSet == '5'):\n",
    "        manuscriptHasEditorialSet_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-hasEditorialSet-aDeterminer'\n",
    "    \n",
    "    \n",
    "    ## -----------------------> manuscriptHasInternalComment\n",
    "    internalComment = row[22]\n",
    "    if (internalComment != ''):\n",
    "        if (\"[Biblio\" in internalComment):\n",
    "            # add link\n",
    "            refbiblio = re.compile(r'\\[(Biblio (\\d+))\\]')\n",
    "            internalComment_link = re.sub(refbiblio, r'<a class=\"salsah-link\" href=\"'+\"ref:\"+r'\\1\">[\\1]</a>', internalComment)\n",
    "            internalComment_linkref = re.sub('ref:Biblio ','ref:biblio_',internalComment_link)\n",
    "            \n",
    "            # isolate biblio_id in the comment \n",
    "            for biblio_number in re.finditer(refbiblio,internalComment_linkref):\n",
    "                biblio_number = biblio_number.group(2)\n",
    "                biblio_id = 'biblio_'+biblio_number\n",
    "                \n",
    "                # find corresponding biblio_id in bibliography xml file and build correspoding bibliographic reference\n",
    "                tree_bibliodata = ET.parse('../INPUT_data/bibliography_id_correspondance.xml')\n",
    "                root = tree_bibliodata.getroot()\n",
    "                for publication in root:\n",
    "                    publication_id = publication.attrib['id']\n",
    "                    if (biblio_id == publication_id):\n",
    "                        namespaces = {'p0112-roud-oeuvres': 'http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#'} \n",
    "                        # TITLE\n",
    "                        ref_publicationHasTitle = publication.findall('./p0112-roud-oeuvres:publicationHasTitle', namespaces)[0].text\n",
    "                        #if len(publicationHasTitle.split()) > 10:  ### it title is too long, take only first 10 words\n",
    "                             # do something\n",
    "                        if (publication.tag == \"{http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#}PeriodicalArticle\" or publication.tag == \"{http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#}BookSection\"):\n",
    "                            ref_title = \"« \"+ref_publicationHasTitle+\" »\"\n",
    "                        else:\n",
    "                            ref_title = \"<i>\"+ref_publicationHasTitle+\"</i>\"\n",
    "                        # AUTHOR    \n",
    "                        ref_publicationHasAuthor = publication.find('./p0112-roud-oeuvres:publicationHasAuthor', namespaces)\n",
    "                        # DATE\n",
    "                        ref_publicationHasDate = publication.find('./p0112-roud-oeuvres:publicationHasDate', namespaces)\n",
    "                        # BIBLIO = AUTHOR + TITLE + DATE\n",
    "                        if (ref_publicationHasAuthor is None):\n",
    "                            if (ref_publicationHasDate is None):\n",
    "                                biblioInInternalComment = ref_title\n",
    "                            else:\n",
    "                                ref_date = publication.findall('./p0112-roud-oeuvres:publicationHasDate', namespaces)[0].text.split(\"GREGORIAN:\")[1].split(\"-\")[0].split(\" CE\")[0]\n",
    "                                biblioInInternalComment = ref_title+\", \"+ref_date\n",
    "                        else:\n",
    "                            ref_author = publication.findall('./p0112-roud-oeuvres:publicationHasAuthor', namespaces)[0].findall('./p0112-roud-oeuvres:Author', namespaces)[0].get('target').split(\"_\")[0]\n",
    "                            if (ref_publicationHasDate is None):\n",
    "                                biblioInInternalComment = ref_author+\", \"+ref_title\n",
    "                            else:\n",
    "                                ref_date = publication.findall('./p0112-roud-oeuvres:publicationHasDate', namespaces)[0].text.split(\"GREGORIAN:\")[1].split(\"-\")[0].split(\" CE\")[0]\n",
    "                                biblioInInternalComment = ref_author+\", \"+ref_title+\", \"+ref_date\n",
    "                # replace [Biblio number] with bibliographic reference\n",
    "                biblioToBeReplaced = '\\[Biblio '+biblio_number+'\\]'\n",
    "                internalComment_linkref = re.sub(biblioToBeReplaced,biblioInInternalComment,internalComment_linkref)\n",
    "            \n",
    "            manuscriptHasInternalComment_content = '<text xmlns=\"\">'+internalComment_linkref+'</text>'\n",
    "        else:\n",
    "            manuscriptHasInternalComment_content = '<text xmlns=\"\">'+internalComment+'</text>'\n",
    "            \n",
    "            \n",
    "    ## -----------------------> manuscriptHasOldShelfmark\n",
    "    oldShelfmark = row[3]\n",
    "    if (oldShelfmark != ''):\n",
    "        manuscriptHasOldShelfmark_content = '<text xmlns=\"\">'+oldShelfmark+'</text>'\n",
    "    \n",
    "    \n",
    "    ## -----------------------> manuscriptHasPublishedReference\n",
    "    publishedRef = row[19]\n",
    "    if (publishedRef != ''):\n",
    "        publishedRef_content = 'biblio_'+publishedRef\n",
    "        \n",
    "\n",
    "    ## -----------------------> manuscriptHasShelfmark\n",
    "    shelfmark = row[4]\n",
    "    if (shelfmark != ''):\n",
    "        manuscriptHasShelfmark_content = '<text xmlns=\"\">'+shelfmark+'</text>'\n",
    "        \n",
    "        \n",
    "    ## -----------------------> manuscriptHasTitle\n",
    "    title = row[1]\n",
    "    if (title != ''):\n",
    "        title = re.sub('<','&#12296;', title)\n",
    "        title = re.sub('>', '&#12297;', title)\n",
    "        title = re.sub('&','&amp;', title)\n",
    "        manuscriptHasTitle_content = '<text xmlns=\"\">'+title+'</text>'\n",
    "        \n",
    "        \n",
    "    ## -----------------------> manuscriptIsDigitized\n",
    "    if (row[21] == 'oui'):\n",
    "        manuscriptIsDigitized_content = 'true'\n",
    "    else:\n",
    "        manuscriptIsDigitized_content = 'false'  \n",
    "        \n",
    "        \n",
    "    ## -----------------------> manuscriptIsInArchive\n",
    "    archive = row[2]\n",
    "    if (archive == '1'):\n",
    "        manuscriptIsInArchive_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-isInArchive-CRLRGR'\n",
    "        manuscriptIsInArchive4label = \"CRLR GR\"\n",
    "    if (archive == '2'):\n",
    "        manuscriptIsInArchive_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-isInArchive-CRLRMermod'\n",
    "        manuscriptIsInArchive4label = \"CRLR Mermod\"\n",
    "    if (archive == '3'):\n",
    "        manuscriptIsInArchive_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-isInArchive-BCUSimond'\n",
    "        manuscriptIsInArchive4label = \"BCU Simond\"\n",
    "    if (archive == '4'):\n",
    "        manuscriptIsInArchive_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-isInArchive-BCUChevalley'\n",
    "        manuscriptIsInArchive4label = \"BCU Chevalley\"\n",
    "    if (archive == '5'):\n",
    "        manuscriptIsInArchive_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-isInArchive-BCUGuildeDuLivre'\n",
    "        manuscriptIsInArchive4label = \"BCU Guilde du livre\"\n",
    "    if (archive == '6'):\n",
    "        manuscriptIsInArchive_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-isInArchive-BCUHutterPerrier'\n",
    "        manuscriptIsInArchive4label = \"BCU Perrier\"\n",
    "    if (archive == '7'):\n",
    "        manuscriptIsInArchive_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-isInArchive-BiblioChauxDeFonds'\n",
    "        manuscriptIsInArchive4label = \"Biblio Chaux-de-fonds\"\n",
    "    if (archive == '8'):\n",
    "        manuscriptIsInArchive_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-isInArchive-CollectionPrivee'\n",
    "        manuscriptIsInArchive4label = \"Collection privée\"\n",
    "    if (archive == '9'):\n",
    "        manuscriptIsInArchive_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-isInArchive-CRLRColomb'\n",
    "        manuscriptIsInArchive4label = \"CRLR Colomb\"\n",
    "    if (archive == '10'):\n",
    "        manuscriptIsInArchive_content = 'http://rdfh.ch/lists/0112/roud-oeuvres-flatlist-isInArchive-CRLRStevenPaulRobert'\n",
    "        manuscriptIsInArchive4label = \"CRLR Steven PR\"\n",
    "    \n",
    "    \n",
    "    ficheLabel = \"fiche\"+'_'+manuscriptIsInArchive4label+' '+shelfmark+' ___ '+title\n",
    "    \n",
    "    \n",
    "   \n",
    "\n",
    "    \n",
    "    \n",
    "    ###################################\n",
    "    ## CREATE ELEMENTS AND ATTRIBUTES (AS PREVIOUSLY DEFINED WITH NS) AND ASSIGN THEM CONTENT\n",
    "    ###################################\n",
    "    \n",
    "    \n",
    "    Manuscript = ET.Element(ManuscriptNS, attrib={'id':ficheid}) \n",
    "    \n",
    "    label = ET.SubElement(Manuscript, labelNS)\n",
    "    label.text = ficheLabel\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> hasAnnotation\n",
    "    hasAnnotation = ET.SubElement(Manuscript, hasAnnotationNS, attrib={'knoraType':'boolean_value'})\n",
    "    hasAnnotation.text = hasAnnotation_content\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> hasDocumentType\n",
    "    hasDocumentType = ET.SubElement(Manuscript, hasDocumentTypeNS, attrib={'knoraType':'hlist_value'})\n",
    "    hasDocumentType.text = hasDocumentType_content\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> hasGeneticStage\n",
    "    if (hasGeneticStage_content == ''):\n",
    "        pass\n",
    "    else:\n",
    "        hasGeneticStage = ET.SubElement(Manuscript, hasGeneticStageNS, attrib={'knoraType':'hlist_value'})\n",
    "        hasGeneticStage.text = hasGeneticStage_content\n",
    "        \n",
    "        \n",
    "    ## -----------------------------> hasOtherWritingTool\n",
    "    if (otherWritingTool != ''):\n",
    "        hasOtherWritingTool = ET.SubElement(Manuscript, hasOtherWritingToolNS, attrib={'knoraType':'richtext_value'})  # , 'mapping_id':'http://rdfh.ch/standoff/mappings/StandardMapping'\n",
    "        ## take the content of hasOtherWritingTool + entities_declaration and transform it into xml, otherwise is string and Knora consider it as string\n",
    "        entities_and_hasOtherWritingTool = ET.fromstring(entities_declaration + hasOtherWritingTool_content)\n",
    "        hasOtherWritingTool.append(entities_and_hasOtherWritingTool)\n",
    "        \n",
    "    \n",
    "    ## -----------------------------> hasPublicComment\n",
    "    if (publicComment != ''):\n",
    "        hasPublicComment = ET.SubElement(Manuscript, hasPublicCommentNS, attrib={'knoraType':'richtext_value'})  # , 'mapping_id':'http://rdfh.ch/standoff/mappings/StandardMapping'\n",
    "        entities_and_hasPublicComment = ET.fromstring(entities_declaration + hasPublicComment_content)\n",
    "        hasPublicComment.append(entities_and_hasPublicComment)\n",
    "        \n",
    "    \n",
    "    ## -----------------------------> hasSupportInfo\n",
    "    if (supportInfo != ''):\n",
    "        hasSupportInfo = ET.SubElement(Manuscript, hasSupportInfoNS, attrib={'knoraType':'richtext_value'})  # , 'mapping_id':'http://rdfh.ch/standoff/mappings/StandardMapping'\n",
    "        entities_and_hasSupportInfo = ET.fromstring(entities_declaration + hasSupportInfo_content)\n",
    "        hasSupportInfo.append(entities_and_hasSupportInfo)\n",
    "        \n",
    "        \n",
    "    ## -----------------------------> hasSupportType\n",
    "    hasSupportType = ET.SubElement(Manuscript, hasSupportTypeNS, attrib={'knoraType':'hlist_value'})\n",
    "    hasSupportType.text = hasSupportType_content\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> hasTranslatedAuthor\n",
    "    if (translatedAuthor != '') and (hasTranslatedAuthor_content != ''):\n",
    "        hasTranslatedAuthor = ET.SubElement(Manuscript, hasTranslatedAuthorNS)\n",
    "        Author = ET.SubElement(hasTranslatedAuthor, AuthorNS, attrib={'knoraType':'link_value', 'linkType':'ref', 'target':hasTranslatedAuthor_content})\n",
    "      \n",
    "    \n",
    "    ## -----------------------------> hasWritingColor\n",
    "    if (hasWritingColor_content !=  ''):\n",
    "        hasWritingColor = ET.SubElement(Manuscript, hasWritingColorNS, attrib={'knoraType':'hlist_value'})\n",
    "        hasWritingColor.text = hasWritingColor_content\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> hasWritingTool\n",
    "    if (hasWritingTool_content != ''):\n",
    "        hasWritingTool = ET.SubElement(Manuscript, hasWritingToolNS, attrib={'knoraType':'hlist_value'})\n",
    "        hasWritingTool.text = hasWritingTool_content\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> isPhotocopy\n",
    "    isPhotocopy = ET.SubElement(Manuscript, isPhotocopyNS, attrib={'knoraType':'boolean_value'})\n",
    "    isPhotocopy.text = isPhotocopy_content\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> manuscriptHasDateComputable\n",
    "    if (date != '' and not date.startswith('0000#')):\n",
    "        manuscriptHasDateComputable = ET.SubElement(Manuscript, manuscriptHasDateComputableNS, attrib={'knoraType':'date_value'})\n",
    "        manuscriptHasDateComputable.text = manuscriptHasDateComputable_content\n",
    "        \n",
    "        \n",
    "    ## -----------------------------> manuscriptHasDateEstablishedComputable\n",
    "    if (datation != ''):\n",
    "        manuscriptHasDateEstablishedComputable = ET.SubElement(Manuscript, manuscriptHasDateEstablishedComputableNS, attrib={'knoraType':'date_value'})\n",
    "        manuscriptHasDateEstablishedComputable.text = manuscriptHasDateEstablishedComputable_content\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> manuscriptHasDateEstablishedList\n",
    "    if (dateEstablishedList != '1'):\n",
    "        manuscriptHasDateEstablishedList = ET.SubElement(Manuscript, manuscriptHasDateEstablishedListNS, attrib={'knoraType':'hlist_value'})\n",
    "        manuscriptHasDateEstablishedList.text = manuscriptHasDateEstablishedList_content\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> manuscriptHasDateEstablishedReadable\n",
    "    if (datation == '' and datation_comment == ''):\n",
    "        pass\n",
    "    else:\n",
    "        manuscriptHasDateEstablishedReadable = ET.SubElement(Manuscript, manuscriptHasDateEstablishedReadableNS, attrib={'knoraType':'richtext_value'}) # NO MAPPING NEEDED\n",
    "        entities_and_manuscriptHasDateEstablishedReadable = ET.fromstring(entities_declaration + manuscriptHasDateEstablishedReadable_content)\n",
    "        manuscriptHasDateEstablishedReadable.append(entities_and_manuscriptHasDateEstablishedReadable)\n",
    " \n",
    "\n",
    "    ## -----------------------------> manuscriptHasDateReadable\n",
    "    if (date != ''):\n",
    "        manuscriptHasDateReadable = ET.SubElement(Manuscript, manuscriptHasDateReadableNS, attrib={'knoraType':'richtext_value'})  # NO MAPPING NEEDED\n",
    "        entities_and_manuscriptHasDateReadable = ET.fromstring(entities_declaration + manuscriptHasDateReadable_content)\n",
    "        manuscriptHasDateReadable.append(entities_and_manuscriptHasDateReadable)\n",
    "    \n",
    "                \n",
    "    ## -----------------------------> manuscriptHasEditorialSet\n",
    "    manuscriptHasEditorialSet = ET.SubElement(Manuscript, manuscriptHasEditorialSetNS, attrib={'knoraType':'hlist_value'})\n",
    "    manuscriptHasEditorialSet.text = manuscriptHasEditorialSet_content\n",
    "    \n",
    "    \n",
    "    ## -----------------------------> manuscriptHasInternalComment\n",
    "    if (internalComment != ''):\n",
    "        manuscriptHasInternalComment = ET.SubElement(Manuscript, manuscriptHasInternalCommentNS, attrib={'knoraType':'richtext_value'})  # , 'mapping_id':'http://rdfh.ch/standoff/mappings/StandardMapping'\n",
    "        entities_and_manuscriptHasInternalComment = ET.fromstring(entities_declaration + manuscriptHasInternalComment_content)\n",
    "        manuscriptHasInternalComment.append(entities_and_manuscriptHasInternalComment)\n",
    "    \n",
    "    ## -----------------------------> manuscriptHasOldShelfmark\n",
    "    if (oldShelfmark != ''):\n",
    "        manuscriptHasOldShelfmark = ET.SubElement(Manuscript, manuscriptHasOldShelfmarkNS, attrib={'knoraType':'richtext_value'})  # NO MAPPING NEEDED\n",
    "        entities_and_manuscriptHasOldShelfmark = ET.fromstring(entities_declaration + manuscriptHasOldShelfmark_content)\n",
    "        manuscriptHasOldShelfmark.append(entities_and_manuscriptHasOldShelfmark)\n",
    "     \n",
    "    \n",
    "    ## -----------------------------> manuscriptHasPublishedReference\n",
    "    if (publishedRef != ''):\n",
    "        manuscriptHasPublishedReference = ET.SubElement(Manuscript, manuscriptHasPublishedReferenceNS)\n",
    "        Publication = ET.SubElement(manuscriptHasPublishedReference, PublicationNS, attrib={'knoraType':'link_value', 'linkType':'ref', 'target':publishedRef_content})\n",
    "\n",
    "        \n",
    "    ## -----------------------------> manuscriptHasShelfmark\n",
    "    if (shelfmark != ''):\n",
    "        manuscriptHasShelfmark = ET.SubElement(Manuscript, manuscriptHasShelfmarkNS, attrib={'knoraType':'richtext_value'}) # NO MAPPING NEEDED\n",
    "        entities_and_manuscriptHasShelfmark = ET.fromstring(entities_declaration + manuscriptHasShelfmark_content)\n",
    "        manuscriptHasShelfmark.append(entities_and_manuscriptHasShelfmark)\n",
    "        \n",
    "        \n",
    "    ## -----------------------------> manuscriptHasTitle\n",
    "    if (title != ''):\n",
    "        manuscriptHasTitle = ET.SubElement(Manuscript, manuscriptHasTitleNS, attrib={'knoraType':'richtext_value'}) # NO MAPPING NEEDED\n",
    "        entities_and_manuscriptHasTitle = ET.fromstring(entities_declaration + manuscriptHasTitle_content)\n",
    "        manuscriptHasTitle.append(entities_and_manuscriptHasTitle)\n",
    "        \n",
    "\n",
    "    ## -----------------------------> manuscriptIsDigitized\n",
    "    manuscriptIsDigitized = ET.SubElement(Manuscript, manuscriptIsDigitizedNS, attrib={'knoraType':'boolean_value'})\n",
    "    manuscriptIsDigitized.text = manuscriptIsDigitized_content\n",
    "\n",
    "    \n",
    "    ## -----------------------------> manuscriptIsInArchive\n",
    "    manuscriptIsInArchive = ET.SubElement(Manuscript, manuscriptIsInArchiveNS, attrib={'knoraType':'hlist_value'})\n",
    "    manuscriptIsInArchive.text = manuscriptIsInArchive_content\n",
    "\n",
    "     \n",
    "    \n",
    "    \n",
    "    tree = ET.tostring(Manuscript, encoding=\"unicode\")\n",
    "    o.write('\\n''\\n'+ tree)\n",
    "\n",
    "## WRITE END OF THE XML FILE\n",
    "with o:  \n",
    "    o.write('\\n'+'</knoraXmlImport:resources>')\n",
    "\n",
    "o.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "### CREATE XML FOR SCANS\n",
    "###\n",
    "\n",
    "\n",
    "from xml.etree import ElementTree as ET\n",
    "import re, csv\n",
    "import glob\n",
    "import os\n",
    "from os import listdir\n",
    "\n",
    "mydir = '/mnt/scanlettMounted/GustaveRoud/E_Scan/Scans_import/FondsArchive/'\n",
    "# /mnt/scanlettMounted/GustaveRoud/E_Scan/Scans_complets/FondsArchive/\n",
    "o = open('../OUTPUT_xml/images.xml', 'w')\n",
    "\n",
    "\n",
    "\n",
    "###################################\n",
    "## WRITE DECLARATIONS AND BEGINNING OF THE XML FILE -adding more line breaks for readibility '+'\\n'+' ???-\n",
    "###################################\n",
    "o.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>'+'\\n'+'<knoraXmlImport:resources xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/knoraXmlImport/v1# ../p0112-roud-oeuvres-xml-schemas/p0112-roud-oeuvres.xsd\" xmlns=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\" xmlns:p0112-roud-oeuvres=\"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\">'+'\\n')\n",
    "\n",
    "\n",
    "    \n",
    "###################################\n",
    "#### REGISTERING NAMESPACES\n",
    "###################################\n",
    "NS_ROUD = \"http://api.knora.org/ontology/0112/roud-oeuvres/xml-import/v1#\" \n",
    "NS_KNORAIMPORT = \"http://api.knora.org/ontology/knoraXmlImport/v1#\"\n",
    "ET.register_namespace(\"p0112-roud-oeuvres\", NS_ROUD)\n",
    "ET.register_namespace(\"knoraXmlImport\", NS_KNORAIMPORT)\n",
    "\n",
    "\n",
    "###################################\n",
    "## DEFINE ELEMENTS WITH NS\n",
    "###################################\n",
    "PageNS = ET.QName(NS_ROUD, \"Page\")\n",
    "labelNS = ET.QName(NS_KNORAIMPORT, \"label\")\n",
    "fileNS = ET.QName(NS_KNORAIMPORT, \"file\")\n",
    "hasSeqnumNS = ET.QName(NS_ROUD, \"hasSeqnum\")\n",
    "pageHasNameNS = ET.QName(NS_ROUD, \"pageHasName\")\n",
    "pageIsPartOfManuscriptNS = ET.QName(NS_ROUD, \"pageIsPartOfManuscript\")\n",
    "ManuscriptNS = ET.QName(NS_ROUD, \"Manuscript\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###################################\n",
    "## PREPARE CONTENT OF ELEMENTS AND ATTRIBUTES\n",
    "###################################\n",
    "\n",
    "\n",
    "\n",
    "dirs = os.listdir(mydir)\n",
    "for eachDir in dirs:\n",
    "    eachPath = mydir+eachDir+'/*.png'  ## attenzione *.tif or *.png\n",
    "    allTif = glob.glob(eachPath)\n",
    "    for eachTif in allTif:\n",
    "        eachTif_splitted = os.path.split(eachTif)\n",
    "        tifName = eachTif_splitted[1]\n",
    "        tifHead = eachTif_splitted[0]\n",
    "        tifCompletePath = eachTif\n",
    "        \n",
    "        \n",
    "        ## -----------------------> Page/@id\n",
    "        tifId = tifName\n",
    "    \n",
    "        ## -----------------------> file/@path\n",
    "        filePath = tifCompletePath\n",
    "        \n",
    "        ## -----------------------> hasSeqnum\n",
    "        seqnum = tifName.rsplit('_',1)[1].split('.',1)[0]\n",
    "        \n",
    "        ## -----------------------> pageHasName\n",
    "        simpleName = tifName.rsplit('_',1)[0].rsplit('_',1)[1]\n",
    "        if re.match(r'\\d', simpleName):\n",
    "            completeName = 'f. '+simpleName\n",
    "        if re.match(r'p', simpleName):\n",
    "            completeName = 'p. '+simpleName.split('p')[1]\n",
    "        if re.match(r'annexe', simpleName):\n",
    "            completeName = 'annexe '+simpleName.split('annexe')[1]\n",
    "        if re.match(r'couv1', simpleName):\n",
    "            completeName = 'annexe '+simpleName.split('annexe')[1]\n",
    "            # TO BE ADDED WHEN COMPLETING IMAGES IMPORT !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "            # if starts with couv\n",
    "            # if starts with doc (a volte ha anche ff., a volte no)\n",
    "            \n",
    "        \n",
    "        ## -----------------------> pageIsPartOfManuscript\n",
    "        coteComplete = tifHead.rsplit('/',1)[1]\n",
    "        fonds = coteComplete.rsplit('_',1)[0]  # first part\n",
    "        fondsReadable = re.sub('_', ' ', fonds)\n",
    "        cote = coteComplete.rsplit('_',1)[1]   # second part\n",
    "        ms = cote[:2]\n",
    "        numb = cote[2:3]\n",
    "        let = cote[3:4]\n",
    "        rest = cote[4:]\n",
    "        coteAsInFiche = ms+' '+numb+' '+let+'/'+rest   # recreate because in naming scans whitespaces and slash have not been used\n",
    "        \n",
    "        # csv downloaded from sparql query (query saved in graphdb). First column: iri, second column: cote \n",
    "        # attention to delimiter for reading csv\n",
    "        with open(\"../INPUT_data/fiche_iri_cote.csv\", 'r') as csv_cote_id_correspondance:     \n",
    "            cote_id_correspondance = csv.reader(csv_cote_id_correspondance, delimiter =',', doublequote=True)\n",
    "            for row in cote_id_correspondance:\n",
    "                if (coteAsInFiche == row[1]):\n",
    "                    ficheTarget = row[0]\n",
    "        \n",
    "        #with open(\"../INPUT_data/fiche_cote-id_correspondance.csv\", 'r') as csv_cote_id_correspondance:     # csv created from backup_fiches (with xsl in /transformationScripts) just to take easily the corresponding id for each shelfmark\n",
    "         #   cote_id_correspondance = csv.reader(csv_cote_id_correspondance, delimiter =';', doublequote=True)\n",
    "          #  for row in cote_id_correspondance:\n",
    "           #     if (coteAsInFiche == row[1]):\n",
    "            #        ficheTarget = row[0]\n",
    "    \n",
    "\n",
    "        ## -----------------------> label\n",
    "        scanLabel = \"page_\"+fondsReadable+\" \"+coteAsInFiche+\"___\"+completeName+\"___\"+seqnum\n",
    "        \n",
    "    \n",
    "    \n",
    "        ###################################\n",
    "        ## CREATE ELEMENTS AND ATTRIBUTES (AS PREVIOUSLY DEFINED WITH NS) AND ASSIGN THEM CONTENT\n",
    "        ###################################\n",
    "\n",
    "\n",
    "        Page = ET.Element(PageNS, attrib={'id':tifId}) \n",
    "        \n",
    "        label = ET.SubElement(Page, labelNS)\n",
    "        label.text = scanLabel\n",
    "    \n",
    "        file = ET.SubElement(Page, fileNS, attrib={'path':filePath, 'mimetype':'image/png'})   ## mimetype: png or tiff !!!\n",
    "        \n",
    "        hasSeqnum = ET.SubElement(Page, hasSeqnumNS, attrib={'knoraType':'int_value'})\n",
    "        hasSeqnum.text = seqnum\n",
    "        \n",
    "        pageHasName = ET.SubElement(Page, pageHasNameNS, attrib={'knoraType':'richtext_value'})\n",
    "        pageHasName.text = completeName\n",
    "        \n",
    "        pageIsPartOfManuscript = ET.SubElement(Page, pageIsPartOfManuscriptNS)\n",
    "        Manuscript = ET.SubElement(pageIsPartOfManuscript, ManuscriptNS, attrib={'knoraType':'link_value', 'linkType':'iri', 'target':ficheTarget})\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        tree = ET.tostring(Page, encoding=\"unicode\")\n",
    "        o.write('\\n''\\n'+ tree)\n",
    "\n",
    "## WRITE END OF THE XML FILE\n",
    "with o:  \n",
    "    o.write('\\n'+'</knoraXmlImport:resources>')\n",
    "\n",
    "o.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
